{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/7sb9_6rs4k14xg5ncv4qnqhm0000gn/T/ipykernel_3855/4220606287.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#Data Understanding and Preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('Fake.csv')\n",
    "true = pd.read_csv('True.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21417"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake)\n",
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "21412  'Fully committed' NATO backs new U.S. approach...   \n",
       "21413  LexisNexis withdrew two products from Chinese ...   \n",
       "21414  Minsk cultural hub becomes haven from authorities   \n",
       "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
       "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text    subject  \\\n",
       "0      Donald Trump just couldn t wish all Americans ...       News   \n",
       "1      House Intelligence Committee Chairman Devin Nu...       News   \n",
       "2      On Friday, it was revealed that former Milwauk...       News   \n",
       "3      On Christmas day, Donald Trump announced that ...       News   \n",
       "4      Pope Francis used his annual Christmas Day mes...       News   \n",
       "...                                                  ...        ...   \n",
       "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...  worldnews   \n",
       "21413  LONDON (Reuters) - LexisNexis, a provider of l...  worldnews   \n",
       "21414  MINSK (Reuters) - In the shadow of disused Sov...  worldnews   \n",
       "21415  MOSCOW (Reuters) - Vatican Secretary of State ...  worldnews   \n",
       "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...  worldnews   \n",
       "\n",
       "                    date  label  \n",
       "0      December 31, 2017      1  \n",
       "1      December 31, 2017      1  \n",
       "2      December 30, 2017      1  \n",
       "3      December 29, 2017      1  \n",
       "4      December 25, 2017      1  \n",
       "...                  ...    ...  \n",
       "21412   August 22, 2017       0  \n",
       "21413   August 22, 2017       0  \n",
       "21414   August 22, 2017       0  \n",
       "21415   August 22, 2017       0  \n",
       "21416   August 22, 2017       0  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['label'] = 1\n",
    "true['label']=0\n",
    "\n",
    "df_concated = pd.concat([fake, true])\n",
    "permutation = np.random.permutation(len(df_concated))\n",
    "df = df_concated.iloc[permutation]\n",
    "df_concated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44689, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = df.isnull().sum()\n",
    "\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17370</th>\n",
       "      <td>HOW A SINGLE FEDERAL BUREAUCRAT OPENED THE DOO...</td>\n",
       "      <td>Meet Alice Miller who single-handedly scr*wed ...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18309</th>\n",
       "      <td>'It's time to talk': EU again urges dialogue i...</td>\n",
       "      <td>STRASBOURG (Reuters) - The EU executive called...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>Trump weighs next executive orders on national...</td>\n",
       "      <td>ABOARD AIR FORCE ONE (Reuters) - U.S. Presiden...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10532</th>\n",
       "      <td>U.S. senators urge Obama to push for female U....</td>\n",
       "      <td>UNITED NATIONS/WASHINGTON (Reuters) - Seven U....</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>Senate intelligence panel to probe Russia hacking</td>\n",
       "      <td>WASHINGTON (Reuters) - The leaders of the Sena...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>Factbox: Trump on Twitter (Sept 20) - Graham-C...</td>\n",
       "      <td>The following statements were posted to the ve...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>Celebrity Gun Nut Threatens To Shoot His Girl...</td>\n",
       "      <td>A man known primarily for posting videos of hi...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Trump Tried To Distance Himself From His ‘Sen...</td>\n",
       "      <td>Remember the name Felix Sater, because it s go...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11056</th>\n",
       "      <td>BRAVO! TED CRUZ To Introduce Bill To Help Trum...</td>\n",
       "      <td>Now one unlikely Senator is about to put forth...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16862</th>\n",
       "      <td>BREAKING: Iran Publicly Humiliates Obama…Unvei...</td>\n",
       "      <td>A clear violation of Obama s lopsided  deal  w...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "17370  HOW A SINGLE FEDERAL BUREAUCRAT OPENED THE DOO...   \n",
       "18309  'It's time to talk': EU again urges dialogue i...   \n",
       "6005   Trump weighs next executive orders on national...   \n",
       "10532  U.S. senators urge Obama to push for female U....   \n",
       "6329   Senate intelligence panel to probe Russia hacking   \n",
       "...                                                  ...   \n",
       "1659   Factbox: Trump on Twitter (Sept 20) - Graham-C...   \n",
       "8977    Celebrity Gun Nut Threatens To Shoot His Girl...   \n",
       "485     Trump Tried To Distance Himself From His ‘Sen...   \n",
       "11056  BRAVO! TED CRUZ To Introduce Bill To Help Trum...   \n",
       "16862  BREAKING: Iran Publicly Humiliates Obama…Unvei...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "17370  Meet Alice Miller who single-handedly scr*wed ...  Government News   \n",
       "18309  STRASBOURG (Reuters) - The EU executive called...        worldnews   \n",
       "6005   ABOARD AIR FORCE ONE (Reuters) - U.S. Presiden...     politicsNews   \n",
       "10532  UNITED NATIONS/WASHINGTON (Reuters) - Seven U....     politicsNews   \n",
       "6329   WASHINGTON (Reuters) - The leaders of the Sena...     politicsNews   \n",
       "...                                                  ...              ...   \n",
       "1659   The following statements were posted to the ve...     politicsNews   \n",
       "8977   A man known primarily for posting videos of hi...             News   \n",
       "485    Remember the name Felix Sater, because it s go...             News   \n",
       "11056  Now one unlikely Senator is about to put forth...         politics   \n",
       "16862  A clear violation of Obama s lopsided  deal  w...  Government News   \n",
       "\n",
       "       label  \n",
       "17370      1  \n",
       "18309      0  \n",
       "6005       0  \n",
       "10532      0  \n",
       "6329       0  \n",
       "...      ...  \n",
       "1659       0  \n",
       "8977       1  \n",
       "485        1  \n",
       "11056      1  \n",
       "16862      1  \n",
       "\n",
       "[44689 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_date = df.drop(columns=['date'])\n",
    "\n",
    "df_no_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make text Preprocessing, where are going through these steps: \n",
    "* Lowercasing\n",
    "* Removing Special Characters and Punctuation\n",
    "* Tokenization\n",
    "* Removing Stopwords\n",
    "* Lemmatization (We'll prefer this over stemming as it's generally more effective for understanding the context of words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mikkelrolf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mikkelrolf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mikkelrolf/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')  # for tokenization\n",
    "nltk.download('stopwords')  # for stopwords\n",
    "nltk.download('wordnet')  # for lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_subject(subject):\n",
    "    # Convert text to lowercase\n",
    "    subject = subject.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    subject = ''.join(char for char in subject if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(subject)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_title(title):\n",
    "    # Convert text to lowercase\n",
    "    title = title.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    title = ''.join(char for char in title if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(title)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it contains a column named 'text'\n",
    "df_no_date['cleaned_text'] = df_no_date['text'].apply(preprocess_text)\n",
    "df_no_date['cleaned_subject'] = df_no_date['subject'].apply(preprocess_subject)\n",
    "df_no_date['cleaned_title'] = df_no_date['title'].apply(preprocess_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_date.drop(columns=['title', 'subject', 'text'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_subject</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17370</th>\n",
       "      <td>1</td>\n",
       "      <td>meet alice miller singlehandedly scrwed legal ...</td>\n",
       "      <td>government news</td>\n",
       "      <td>single federal bureaucrat opened door let fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18309</th>\n",
       "      <td>0</td>\n",
       "      <td>strasbourg reuters eu executive called wednesd...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>time talk eu urge dialogue spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>0</td>\n",
       "      <td>aboard air force one reuters u president donal...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>trump weighs next executive order national sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10532</th>\n",
       "      <td>0</td>\n",
       "      <td>united nationswashington reuters seven u woman...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>u senator urge obama push female un secretaryg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>0</td>\n",
       "      <td>washington reuters leader senate intelligence ...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>senate intelligence panel probe russia hacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>0</td>\n",
       "      <td>following statement posted verified twitter ac...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>factbox trump twitter sept 20 grahamcassidy bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>1</td>\n",
       "      <td>man known primarily posting video making sound...</td>\n",
       "      <td>news</td>\n",
       "      <td>celebrity gun nut threatens shoot girlfriend g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "      <td>remember name felix sater going come lot rober...</td>\n",
       "      <td>news</td>\n",
       "      <td>trump tried distance senior advisor promised r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11056</th>\n",
       "      <td>1</td>\n",
       "      <td>one unlikely senator put forth bill paving way...</td>\n",
       "      <td>politics</td>\n",
       "      <td>bravo ted cruz introduce bill help trump keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16862</th>\n",
       "      <td>1</td>\n",
       "      <td>clear violation obama lopsided deal iran hey b...</td>\n",
       "      <td>government news</td>\n",
       "      <td>breaking iran publicly humiliates obamaunveils...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text  \\\n",
       "17370      1  meet alice miller singlehandedly scrwed legal ...   \n",
       "18309      0  strasbourg reuters eu executive called wednesd...   \n",
       "6005       0  aboard air force one reuters u president donal...   \n",
       "10532      0  united nationswashington reuters seven u woman...   \n",
       "6329       0  washington reuters leader senate intelligence ...   \n",
       "...      ...                                                ...   \n",
       "1659       0  following statement posted verified twitter ac...   \n",
       "8977       1  man known primarily posting video making sound...   \n",
       "485        1  remember name felix sater going come lot rober...   \n",
       "11056      1  one unlikely senator put forth bill paving way...   \n",
       "16862      1  clear violation obama lopsided deal iran hey b...   \n",
       "\n",
       "       cleaned_subject                                      cleaned_title  \n",
       "17370  government news  single federal bureaucrat opened door let fore...  \n",
       "18309        worldnews                   time talk eu urge dialogue spain  \n",
       "6005      politicsnews  trump weighs next executive order national sec...  \n",
       "10532     politicsnews  u senator urge obama push female un secretaryg...  \n",
       "6329      politicsnews     senate intelligence panel probe russia hacking  \n",
       "...                ...                                                ...  \n",
       "1659      politicsnews  factbox trump twitter sept 20 grahamcassidy bi...  \n",
       "8977              news  celebrity gun nut threatens shoot girlfriend g...  \n",
       "485               news  trump tried distance senior advisor promised r...  \n",
       "11056         politics  bravo ted cruz introduce bill help trump keep ...  \n",
       "16862  government news  breaking iran publicly humiliates obamaunveils...  \n",
       "\n",
       "[44689 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_date.to_csv('Preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'cleaned_text': 0\n"
     ]
    }
   ],
   "source": [
    "#i got an error that indicated that i had NaN in my dataset, thats why i have the code below to identify NaN\n",
    "\n",
    "nan_count = df_no_date['cleaned_text'].isna().sum()\n",
    "print(f\"Number of NaN values in 'cleaned_text': {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/7sb9_6rs4k14xg5ncv4qnqhm0000gn/T/ipykernel_1843/342025918.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Load your DataFrame\n",
    "news_df = pd.read_csv('Preprocessed_NoText.csv')\n",
    "\n",
    "# Ensure all text data are strings and handle any NaN values\n",
    "news_df['cleaned_text'] = news_df['cleaned_text'].astype(str).fillna('')\n",
    "\n",
    "# Initialize vectorizers\n",
    "bow_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Apply Bag of Words model\n",
    "bow_features = bow_vectorizer.fit_transform(news_df['cleaned_text'])\n",
    "\n",
    "# Apply TF-IDF model\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(news_df['cleaned_text'])\n",
    "\n",
    "# Convert BoW features into a DataFrame\n",
    "bow_df = pd.DataFrame(bow_features.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Convert TF-IDF features into a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_df = pd.concat([news_df, bow_df], axis=1)\n",
    "\n",
    "# Save or print your DataFrames\n",
    "news_df.to_csv('news.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "news_df = pd.concat([news_df, tfidf_df, bow_df], axis=1)\n",
    "\n",
    "# Save or print your DataFrames\n",
    "news_df.to_csv('news.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load your DataFrame\n",
    "ngram_df = pd.read_csv('Preprocessed_NoText.csv')\n",
    "\n",
    "# Initialize a CountVectorizer for generating bigrams\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))  # Set ngram_range to generate bigrams\n",
    "\n",
    "# Apply bigrams model\n",
    "bigram_features = bigram_vectorizer.fit_transform(news_df['cleaned_text'])\n",
    "\n",
    "# Convert bigram features into a DataFrame\n",
    "bigram_df = pd.DataFrame(bigram_features.toarray(), columns=bigram_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the bigram DataFrame with the original news_df DataFrame\n",
    "news_df = pd.concat([news_df, bigram_df], axis=1)\n",
    "\n",
    "# Display the updated DataFrame with bigram features\n",
    "print(news_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
