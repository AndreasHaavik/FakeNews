{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>donald trump met member nato go well moment ar...</td>\n",
       "      <td>watch trump shove foreign leader way get front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>washington reuters rick perry presidentelect d...</td>\n",
       "      <td>trump energy pick perry softens stance climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>president obama blasted republican presidentia...</td>\n",
       "      <td>obama finally build border wallbut there one p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male idaho republican five daughter made creep...</td>\n",
       "      <td>republican lawmaker say rape wont cause pregna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kellyanne conway tried spin white house press ...</td>\n",
       "      <td>watch chuck todd swat annoying kellyanne conwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13829</th>\n",
       "      <td>0</td>\n",
       "      <td>washington reuters member u congress party fri...</td>\n",
       "      <td>u lawmaker back syria strike demand plan trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13830</th>\n",
       "      <td>1</td>\n",
       "      <td>far video 530000 view make content legitimate ...</td>\n",
       "      <td>ups secretly fly refugee u middle east watch g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13831</th>\n",
       "      <td>0</td>\n",
       "      <td>dec 27 story corrects say 55000 page email ins...</td>\n",
       "      <td>u appeal court revives clinton email suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13832</th>\n",
       "      <td>0</td>\n",
       "      <td>madrid reuters spain high court said tuesday g...</td>\n",
       "      <td>spanish court grant u extradition russian hack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13833</th>\n",
       "      <td>1</td>\n",
       "      <td>woman fox news sick tired putting sexist bulls...</td>\n",
       "      <td>fox news collapsing like house card andrea tan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13834 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text  \\\n",
       "0          1  donald trump met member nato go well moment ar...   \n",
       "1          0  washington reuters rick perry presidentelect d...   \n",
       "2          1  president obama blasted republican presidentia...   \n",
       "3          1  male idaho republican five daughter made creep...   \n",
       "4          1  kellyanne conway tried spin white house press ...   \n",
       "...      ...                                                ...   \n",
       "13829      0  washington reuters member u congress party fri...   \n",
       "13830      1  far video 530000 view make content legitimate ...   \n",
       "13831      0  dec 27 story corrects say 55000 page email ins...   \n",
       "13832      0  madrid reuters spain high court said tuesday g...   \n",
       "13833      1  woman fox news sick tired putting sexist bulls...   \n",
       "\n",
       "                                           cleaned_title  \n",
       "0      watch trump shove foreign leader way get front...  \n",
       "1      trump energy pick perry softens stance climate...  \n",
       "2      obama finally build border wallbut there one p...  \n",
       "3      republican lawmaker say rape wont cause pregna...  \n",
       "4      watch chuck todd swat annoying kellyanne conwa...  \n",
       "...                                                  ...  \n",
       "13829     u lawmaker back syria strike demand plan trump  \n",
       "13830  ups secretly fly refugee u middle east watch g...  \n",
       "13831          u appeal court revives clinton email suit  \n",
       "13832  spanish court grant u extradition russian hack...  \n",
       "13833  fox news collapsing like house card andrea tan...  \n",
       "\n",
       "[13834 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load text dataset\n",
    "text_df = pd.read_csv('text_dataset.csv')\n",
    "columns_to_drop_text = ['token_count', 'cleaned_subject']\n",
    "text_df.drop(columns_to_drop_text, axis=1, inplace=True)\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label             int64\n",
       "cleaned_text     object\n",
       "cleaned_title    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize text columns and combine in feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the text columns\n",
    "tfidf_vectorizer_text = TfidfVectorizer()\n",
    "tfidf_vectorizer_subject = TfidfVectorizer()\n",
    "tfidf_vectorizer_title = TfidfVectorizer()\n",
    "\n",
    "# transform each column\n",
    "X_tfidf_text = tfidf_vectorizer_text.fit_transform(text_df['cleaned_text'])\n",
    "# This is if for testing the models without cleaned_subject\n",
    "# X_tfidf_subject = tfidf_vectorizer_subject.fit_transform(text_df['cleaned_subject'])\n",
    "X_tfidf_title = tfidf_vectorizer_title.fit_transform(text_df['cleaned_title'])\n",
    "\n",
    "# Combine TF-IDF from each column into feature matrix\n",
    "X_tfidf_combined = hstack([X_tfidf_text, X_tfidf_title])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label\n",
    "y = text_df['label']\n",
    "\n",
    "# split into test and train where test i 20% and train is 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_combined, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4889772316588363\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66      1353\n",
      "           1       0.00      0.00      0.00      1414\n",
      "\n",
      "    accuracy                           0.49      2767\n",
      "   macro avg       0.24      0.50      0.33      2767\n",
      "weighted avg       0.24      0.49      0.32      2767\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train a baseline model (Dummy Classifier)\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")  # You can change the strategy as needed\n",
    "dummy_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = dummy_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9508492952656307\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1353\n",
      "           1       0.97      0.93      0.95      1414\n",
      "\n",
      "    accuracy                           0.95      2767\n",
      "   macro avg       0.95      0.95      0.95      2767\n",
      "weighted avg       0.95      0.95      0.95      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that includes vectorization and the classifier\n",
    "pipeline_MNNB = Pipeline([\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_MNNB.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline_MNNB.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing GridSearch to find optimal parameters and apply these to optimize the MultinomialNB's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best score: 0.968\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.01\n",
      "Test Accuracy: 0.9696422117817131\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1353\n",
      "           1       0.97      0.97      0.97      1414\n",
      "\n",
      "    accuracy                           0.97      2767\n",
      "   macro avg       0.97      0.97      0.97      2767\n",
      "weighted avg       0.97      0.97      0.97      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'clf__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline_MNNB, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit it to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: %.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Evaluate the best grid search pipeline on the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train Logistic Regression model AND Analyzing the performance by using performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1353\n",
      "           1       0.99      0.99      0.99      1414\n",
      "\n",
      "    accuracy                           0.99      2767\n",
      "   macro avg       0.99      0.99      0.99      2767\n",
      "weighted avg       0.99      0.99      0.99      2767\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1336   17]\n",
      " [  19 1395]]\n",
      "Accuracy Score: 0.9869895193350199\n"
     ]
    }
   ],
   "source": [
    "# Creating a pipeline with TF-IDF Vectorizer and Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  # Convert text to TF-IDF coefficients\n",
    "    ('clf', LogisticRegression(random_state=42))  # Classifier\n",
    "])\n",
    "\n",
    "# Fit the model on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Output performance metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive features:  [('video', 6.162876491746599), ('breaking', 3.6985649780144176), ('hillary', 3.369676459161335), ('gop', 2.8363720631241116), ('watch', 2.7377581136974167), ('21st', 2.1562746673284106), ('muslim', 1.9750855494219133), ('america', 1.9425282633310499), ('obamas', 1.8179421238040867), ('obama', 1.791211449058231)]\n",
      "Top 10 negative features:  [('lawmaker', -1.252729299187331), ('urge', -1.3153801668062934), ('talk', -1.4516531470914145), ('probe', -1.5403459599654779), ('china', -1.550531298196075), ('seek', -1.6031305924872423), ('declined', -1.6823937525440706), ('exclusive', -1.858790483833708), ('say', -2.34705035471496), ('factbox', -2.716477078020587)]\n"
     ]
    }
   ],
   "source": [
    "# get coefficients of the model for interpretation\n",
    "feature_names = tfidf_vectorizer_text.get_feature_names_out().tolist() \\\n",
    "                + tfidf_vectorizer_title.get_feature_names_out().tolist()\n",
    "\n",
    "coefficients = logistic_regression_model.coef_.flatten()\n",
    "\n",
    "feature_importance = dict(zip(feature_names, coefficients))\n",
    "\n",
    "# Sort features by their values\n",
    "sorted_feature_importance = sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# top 10 positive and top 10 negative coefficients\n",
    "print(\"Top 10 positive features: \", sorted_feature_importance[:10])\n",
    "print(\"Top 10 negative features: \", sorted_feature_importance[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   1.7s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   1.8s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   1.8s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   1.9s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   1.9s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   2.5s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   2.5s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   2.6s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   2.2s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   2.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   2.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   2.6s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   2.7s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   2.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   2.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   2.7s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   2.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   1.7s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   1.9s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   2.5s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   2.5s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   2.3s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   2.5s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   2.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   1.7s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   2.4s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   2.3s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   2.4s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   2.9s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   3.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   3.2s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   2.3s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   1.7s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   2.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   3.9s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   4.6s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   4.4s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   3.7s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   4.7s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   2.8s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   3.4s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   2.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   1.9s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   6.9s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   7.3s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   3.5s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   3.6s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   3.7s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   2.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   2.2s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   2.9s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   3.6s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   2.5s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   2.5s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   4.4s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   3.9s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   3.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/andreasmaskine/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.89057487        nan 0.94515165        nan 0.96231985\n",
      "        nan 0.97957871        nan 0.98933766        nan 0.99060263]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__C': 100, 'clf__penalty': 'l2'}\n",
      "Best Score: 0.9906026269179697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1353\n",
      "           1       1.00      0.99      0.99      1414\n",
      "\n",
      "    accuracy                           0.99      2767\n",
      "   macro avg       0.99      0.99      0.99      2767\n",
      "weighted avg       0.99      0.99      0.99      2767\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1348    5]\n",
      " [  10 1404]]\n",
      "Accuracy Score: 0.9945789663895916\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of all values you want to test for C and penalty\n",
    "param_grid = {\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Use 'clf__C' instead of 'logreg__C'\n",
    "    'clf__penalty': ['l1', 'l2']  # Use 'clf__penalty' instead of 'logreg__penalty'\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best parameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model with your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Optionally, evaluate the model on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9873509215757138\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1353\n",
      "           1       0.99      0.98      0.99      1414\n",
      "\n",
      "    accuracy                           0.99      2767\n",
      "   macro avg       0.99      0.99      0.99      2767\n",
      "weighted avg       0.99      0.99      0.99      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use gridSearch to find and use  the optimal hyperparameters, to increase the performance of the Random Forest model even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Best Score: 0.9865365501039126\n",
      "Accuracy: 0.9877123238164076\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1353\n",
      "           1       0.99      0.98      0.99      1414\n",
      "\n",
      "    accuracy                           0.99      2767\n",
      "   macro avg       0.99      0.99      0.99      2767\n",
      "weighted avg       0.99      0.99      0.99      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and validation sets, tokenizing the text, and converting labels into a fitting format.\n",
    "# Split data into training and validation sets\n",
    "train_df, val_df = train_test_split(text_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Encode the texts using tokenizer\n",
    "        encoding = tokenizer(text, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = NewsDataset(train_df['cleaned_text'].tolist(), train_df['label'].tolist())\n",
    "val_dataset = NewsDataset(val_df['cleaned_text'].tolist(), val_df['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating data loaders to handle batching and shuffling the data for training and validation.\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Initializing a BERT pre-trained model\n",
    "BERTmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claramillekalo/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 692/692 [5:36:41<00:00, 29.19s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.05537884194423065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Below we define the training process, including forward and backward propagation.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BERTmodel.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Train the model (example for one epoch)\n",
    "loss = train_epoch(model, train_loader, optimizer)\n",
    "print(f\"Training loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 173/173 [17:06<00:00,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.004552477456523628, Accuracy: 0.9992771955186122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we evaluate the model on the validation/test set\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            correct_predictions += torch.sum(predictions == batch['labels'])\n",
    "\n",
    "    return total_loss / len(data_loader), correct_predictions.double() / len(data_loader.dataset)\n",
    "\n",
    "val_loss, val_accuracy = evaluate(model, val_loader)\n",
    "print(f\"Validation loss: {val_loss}, Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the model - right now commented out as it creates a big file that cannot be pushed to GitHub\n",
    "#torch.save(model.state_dict(), 'bert_news_classifier.pth')\n",
    "#model.load_state_dict(torch.load('bert_news_classifier.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('svc', SVC(kernel='linear'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As SVM processes numerical values, we need to convert the text into numerical values.\n",
    "# we do so by using TF-IDF\n",
    "pipeline_svm = make_pipeline(\n",
    "    SVC(kernel='linear', C=1.0)\n",
    ")\n",
    "#We use a linear kernel for SVM as it is efficient in high-dimensional data which is typical of text data\n",
    "\n",
    "#Now we fit the model:\n",
    "pipeline_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9949403686302855\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1353\n",
      "           1       1.00      0.99      1.00      1414\n",
      "\n",
      "    accuracy                           0.99      2767\n",
      "   macro avg       0.99      1.00      0.99      2767\n",
      "weighted avg       0.99      0.99      0.99      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline_svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best score: 0.994\n",
      "Best parameters set:\n",
      "\tsvc__C: 1\n",
      "Test Accuracy: 0.9949403686302855\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1353\n",
      "           1       1.00      0.99      1.00      1414\n",
      "\n",
      "    accuracy                           0.99      2767\n",
      "   macro avg       0.99      1.00      0.99      2767\n",
      "weighted avg       0.99      0.99      0.99      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'svc__C': [0.01, 0.1, 1, 10, 100]  # Different values for C to control regularization\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline_svm, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit it to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(\"Best score: %.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Evaluate the best grid search pipeline on the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8995cc79525bd2f03bf06fe7351d86fcc477a350b98b661267de2f13aa6250"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
