{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_subject</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>donald trump met member nato go well moment ar...</td>\n",
       "      <td>news</td>\n",
       "      <td>watch trump shove foreign leader way get front...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>washington reuters rick perry presidentelect d...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>trump energy pick perry softens stance climate...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>president obama blasted republican presidentia...</td>\n",
       "      <td>politics</td>\n",
       "      <td>obama finally build border wallbut there one p...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male idaho republican five daughter made creep...</td>\n",
       "      <td>news</td>\n",
       "      <td>republican lawmaker say rape wont cause pregna...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kellyanne conway tried spin white house press ...</td>\n",
       "      <td>news</td>\n",
       "      <td>watch chuck todd swat annoying kellyanne conwa...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                       cleaned_text cleaned_subject  \\\n",
       "0      1  donald trump met member nato go well moment ar...            news   \n",
       "1      0  washington reuters rick perry presidentelect d...    politicsnews   \n",
       "2      1  president obama blasted republican presidentia...        politics   \n",
       "3      1  male idaho republican five daughter made creep...            news   \n",
       "4      1  kellyanne conway tried spin white house press ...            news   \n",
       "\n",
       "                                       cleaned_title  token_count  \n",
       "0  watch trump shove foreign leader way get front...           71  \n",
       "1  trump energy pick perry softens stance climate...          128  \n",
       "2  obama finally build border wallbut there one p...           81  \n",
       "3  republican lawmaker say rape wont cause pregna...           82  \n",
       "4  watch chuck todd swat annoying kellyanne conwa...           75  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv('text_dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9584387423202024\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1353\n",
      "           1       0.97      0.95      0.96      1414\n",
      "\n",
      "    accuracy                           0.96      2767\n",
      "   macro avg       0.96      0.96      0.96      2767\n",
      "weighted avg       0.96      0.96      0.96      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('text_dataset.csv')\n",
    "\n",
    "# Assume you have columns named 'text' for the text data and 'label' for the labels\n",
    "X = df['cleaned_text']  # Replace 'text' with the actual column name containing text data\n",
    "y = df['label']  # Replace 'label' with the actual column name for labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes vectorization and the classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>TTR</th>\n",
       "      <th>text_polarity</th>\n",
       "      <th>text_subjectivity</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>doc_perplexity</th>\n",
       "      <th>1_grams</th>\n",
       "      <th>average_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.524184</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.867938</td>\n",
       "      <td>['donald', 'trump', 'met', 'member', 'nato', '...</td>\n",
       "      <td>6.490826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683438</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.343395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882860</td>\n",
       "      <td>['washington', 'reuters', 'rick', 'perry', 'pr...</td>\n",
       "      <td>6.385744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.721030</td>\n",
       "      <td>0.073622</td>\n",
       "      <td>0.401345</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.883760</td>\n",
       "      <td>['president', 'obama', 'blasted', 'republican'...</td>\n",
       "      <td>6.072961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.667638</td>\n",
       "      <td>0.037264</td>\n",
       "      <td>0.462935</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.882882</td>\n",
       "      <td>['male', 'idaho', 'republican', 'daughter', 'c...</td>\n",
       "      <td>6.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.628032</td>\n",
       "      <td>-0.018966</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.883120</td>\n",
       "      <td>['kellyanne', 'conway', 'tried', 'spin', 'whit...</td>\n",
       "      <td>6.296496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label       TTR  text_polarity  text_subjectivity  title_polarity  \\\n",
       "0      1  0.844037       0.091481           0.524184          -0.125   \n",
       "1      0  0.683438       0.003001           0.343395           0.000   \n",
       "2      1  0.721030       0.073622           0.401345           0.000   \n",
       "3      1  0.667638       0.037264           0.462935           0.000   \n",
       "4      1  0.628032      -0.018966           0.479310          -0.800   \n",
       "\n",
       "   title_subjectivity  doc_perplexity  \\\n",
       "0               0.125        0.867938   \n",
       "1               0.000        0.882860   \n",
       "2               1.000        0.883760   \n",
       "3               1.000        0.882882   \n",
       "4               0.900        0.883120   \n",
       "\n",
       "                                             1_grams  average_word_length  \n",
       "0  ['donald', 'trump', 'met', 'member', 'nato', '...             6.490826  \n",
       "1  ['washington', 'reuters', 'rick', 'perry', 'pr...             6.385744  \n",
       "2  ['president', 'obama', 'blasted', 'republican'...             6.072961  \n",
       "3  ['male', 'idaho', 'republican', 'daughter', 'c...             6.469388  \n",
       "4  ['kellyanne', 'conway', 'tried', 'spin', 'whit...             6.296496  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                    int64\n",
      "TTR                    float64\n",
      "text_polarity          float64\n",
      "text_subjectivity      float64\n",
      "title_polarity         float64\n",
      "title_subjectivity     float64\n",
      "doc_perplexity         float64\n",
      "1_grams                 object\n",
      "average_word_length    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorize the text data directly\n",
    "X_vectorized = vectorizer.fit_transform(df['1_grams'])\n",
    "\n",
    "# Assuming you have other numeric features that need to be included\n",
    "# Drop the non-numeric column and convert DataFrame to a sparse DataFrame to concatenate with X_vectorized\n",
    "df_dropped = df.drop('1_grams', axis=1).astype(float)  # Convert other columns to float\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "df_dropped_sparse = csr_matrix(df_dropped.values)  # Convert DataFrame to sparse matrix\n",
    "X_final = hstack([df_dropped_sparse, X_vectorized])  # Concatenate the matrices\n",
    "\n",
    "# Proceed with your model training using X_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import ast\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('features_dataset.csv')  # Adjust path as necessary\n",
    "\n",
    "# Safe evaluation and conversion function for string representations of lists\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return ' '.join(ast.literal_eval(x))\n",
    "    except:\n",
    "        return x  # return the original string if conversion fails\n",
    "\n",
    "# Apply conversion to the '1_grams' column\n",
    "df['1_grams'] = df['1_grams'].apply(safe_eval)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorize the text data\n",
    "X_vectorized = vectorizer.fit_transform(df['1_grams'])\n",
    "\n",
    "# Assuming you have other numeric features that need to be included\n",
    "df_dropped = df.drop('1_grams', axis=1).astype(float)  # Convert other columns to float\n",
    "df_dropped_sparse = csr_matrix(df_dropped.values)  # Convert DataFrame to sparse matrix\n",
    "\n",
    "# Concatenate the matrices\n",
    "X_final = hstack([df_dropped_sparse, X_vectorized])\n",
    "\n",
    "# Assuming the label column is named 'label'\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with negative values and their counts:\n",
      "text_polarity: 3097 negatives\n",
      "title_polarity: 3117 negatives\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('features_dataset.csv')  # Adjust the path as necessary\n",
    "\n",
    "# Function to safely convert columns to numeric and check for negative values\n",
    "def check_negatives(dataframe):\n",
    "    negative_counts = {}\n",
    "    for column in dataframe.columns:\n",
    "        # Convert column to numeric, non-convertible values become NaN\n",
    "        converted_column = pd.to_numeric(dataframe[column], errors='coerce')\n",
    "        # Count negative values\n",
    "        count = (converted_column < 0).sum()\n",
    "        if count > 0:\n",
    "            negative_counts[column] = count\n",
    "    return negative_counts\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "negative_columns = check_negatives(df)\n",
    "\n",
    "# Print the columns with negative values and their counts\n",
    "print(\"Columns with negative values and their counts:\")\n",
    "for column, count in negative_columns.items():\n",
    "    print(f\"{column}: {count} negatives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_negatives_exclude_non_numeric(dataframe):\n",
    "    negative_counts = {}\n",
    "    for column in dataframe.columns:\n",
    "        # Attempt to convert column to numeric\n",
    "        converted_column = pd.to_numeric(dataframe[column], errors='coerce')\n",
    "        # Continue only if the column is numeric\n",
    "        if converted_column.dtype != 'object':\n",
    "            # Count negative values\n",
    "            count = (converted_column < 0).sum()\n",
    "            if count > 0:\n",
    "                negative_counts[column] = count\n",
    "    return negative_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6176364293458619\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.64      1353\n",
      "           1       0.65      0.53      0.59      1414\n",
      "\n",
      "    accuracy                           0.62      2767\n",
      "   macro avg       0.62      0.62      0.62      2767\n",
      "weighted avg       0.62      0.62      0.62      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('features_dataset.csv')  # Adjust the path as necessary\n",
    "\n",
    "# Convert all columns to numeric, handling non-numeric gracefully\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values that result from conversion errors\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data to scale each feature to [0, 1] range\n",
    "df_scaled = scaler.fit_transform(df.drop('label', axis=1))\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_scaled\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 10}\n",
      "Best cross-validation score: 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameters grid to search\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit it to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6176364293458619\n",
      "Confusion Matrix:\n",
      " [[954 399]\n",
      " [659 755]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.64      1353\n",
      "           1       0.65      0.53      0.59      1414\n",
      "\n",
      "    accuracy                           0.62      2767\n",
      "   macro avg       0.62      0.62      0.62      2767\n",
      "weighted avg       0.62      0.62      0.62      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame and you have already vectorized your features into X and extracted y\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier with the best parameters found\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "model = MultinomialNB(alpha=best_alpha)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
