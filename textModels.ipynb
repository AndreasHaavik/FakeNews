{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_subject</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>donald trump met member nato go well moment ar...</td>\n",
       "      <td>news</td>\n",
       "      <td>watch trump shove foreign leader way get front...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>washington reuters rick perry presidentelect d...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>trump energy pick perry softens stance climate...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>president obama blasted republican presidentia...</td>\n",
       "      <td>politics</td>\n",
       "      <td>obama finally build border wallbut there one p...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male idaho republican five daughter made creep...</td>\n",
       "      <td>news</td>\n",
       "      <td>republican lawmaker say rape wont cause pregna...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kellyanne conway tried spin white house press ...</td>\n",
       "      <td>news</td>\n",
       "      <td>watch chuck todd swat annoying kellyanne conwa...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13829</th>\n",
       "      <td>0</td>\n",
       "      <td>washington reuters member u congress party fri...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>u lawmaker back syria strike demand plan trump</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13830</th>\n",
       "      <td>1</td>\n",
       "      <td>far video 530000 view make content legitimate ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>ups secretly fly refugee u middle east watch g...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13831</th>\n",
       "      <td>0</td>\n",
       "      <td>dec 27 story corrects say 55000 page email ins...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>u appeal court revives clinton email suit</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13832</th>\n",
       "      <td>0</td>\n",
       "      <td>madrid reuters spain high court said tuesday g...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>spanish court grant u extradition russian hack...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13833</th>\n",
       "      <td>1</td>\n",
       "      <td>woman fox news sick tired putting sexist bulls...</td>\n",
       "      <td>news</td>\n",
       "      <td>fox news collapsing like house card andrea tan...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13834 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text  \\\n",
       "0          1  donald trump met member nato go well moment ar...   \n",
       "1          0  washington reuters rick perry presidentelect d...   \n",
       "2          1  president obama blasted republican presidentia...   \n",
       "3          1  male idaho republican five daughter made creep...   \n",
       "4          1  kellyanne conway tried spin white house press ...   \n",
       "...      ...                                                ...   \n",
       "13829      0  washington reuters member u congress party fri...   \n",
       "13830      1  far video 530000 view make content legitimate ...   \n",
       "13831      0  dec 27 story corrects say 55000 page email ins...   \n",
       "13832      0  madrid reuters spain high court said tuesday g...   \n",
       "13833      1  woman fox news sick tired putting sexist bulls...   \n",
       "\n",
       "      cleaned_subject                                      cleaned_title  \\\n",
       "0                news  watch trump shove foreign leader way get front...   \n",
       "1        politicsnews  trump energy pick perry softens stance climate...   \n",
       "2            politics  obama finally build border wallbut there one p...   \n",
       "3                news  republican lawmaker say rape wont cause pregna...   \n",
       "4                news  watch chuck todd swat annoying kellyanne conwa...   \n",
       "...               ...                                                ...   \n",
       "13829    politicsnews     u lawmaker back syria strike demand plan trump   \n",
       "13830        politics  ups secretly fly refugee u middle east watch g...   \n",
       "13831    politicsnews          u appeal court revives clinton email suit   \n",
       "13832       worldnews  spanish court grant u extradition russian hack...   \n",
       "13833            news  fox news collapsing like house card andrea tan...   \n",
       "\n",
       "       token_count  \n",
       "0               71  \n",
       "1              128  \n",
       "2               81  \n",
       "3               82  \n",
       "4               75  \n",
       "...            ...  \n",
       "13829          107  \n",
       "13830          110  \n",
       "13831           82  \n",
       "13832           75  \n",
       "13833           73  \n",
       "\n",
       "[13834 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('text_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize text columns and combine in feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# vectorize the text columns\n",
    "tfidf_vectorizer_text = TfidfVectorizer()\n",
    "tfidf_vectorizer_subject = TfidfVectorizer()\n",
    "tfidf_vectorizer_title = TfidfVectorizer()\n",
    "\n",
    "# transform each column\n",
    "X_tfidf_text = tfidf_vectorizer_text.fit_transform(df['cleaned_text'])\n",
    "X_tfidf_subject = tfidf_vectorizer_subject.fit_transform(df['cleaned_subject'])\n",
    "X_tfidf_title = tfidf_vectorizer_title.fit_transform(df['cleaned_title'])\n",
    "\n",
    "# Combine TF-IDF from each column into feature matrix\n",
    "X_tfidf_combined = hstack([X_tfidf_text, X_tfidf_subject, X_tfidf_title])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label\n",
    "y = df['label']\n",
    "\n",
    "# split into test and train where test i 20% and train is 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_combined, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1353\n",
      "           1       1.00      1.00      1.00      1414\n",
      "\n",
      "    accuracy                           1.00      2767\n",
      "   macro avg       1.00      1.00      1.00      2767\n",
      "weighted avg       1.00      1.00      1.00      2767\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1353    0]\n",
      " [   0 1414]]\n",
      "Accuracy Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive features:  [('leftnews', 3.1685862579653468), ('middleeast', 2.276133256583355), ('usnews', 2.201176797923478), ('video', 0.3731530093545749), ('hillary', 0.24366927717940456), ('21st', 0.18112835199749105), ('obama', 0.1574365553299408), ('news', 0.13447411588866431), ('america', 0.1343298434437592), ('breaking', 0.12883778597317186)]\n",
      "Top 10 negative features:  [('un', -0.10081584397879031), ('korea', -0.10814361379029246), ('eu', -0.11754634424191325), ('talk', -0.12023033263341393), ('factbox', -0.12198750600743422), ('north', -0.12292501364018923), ('china', -0.1354714561320958), ('say', -0.21406711602602185), ('worldnews', -7.697705389075868), ('politicsnews', -8.218068352560541)]\n"
     ]
    }
   ],
   "source": [
    "# get coefficients of the model for interpretation\n",
    "feature_names = tfidf_vectorizer_text.get_feature_names_out().tolist() \\\n",
    "                + tfidf_vectorizer_subject.get_feature_names_out().tolist() \\\n",
    "                + tfidf_vectorizer_title.get_feature_names_out().tolist()\n",
    "\n",
    "coefficients = logistic_regression_model.coef_.flatten()\n",
    "\n",
    "feature_importance = dict(zip(feature_names, coefficients))\n",
    "\n",
    "# Sort features by their values\n",
    "sorted_feature_importance = sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# top 10 positive and top 10 negative coefficients\n",
    "print(\"Top 10 positive features: \", sorted_feature_importance[:10])\n",
    "print(\"Top 10 negative features: \", sorted_feature_importance[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/claratruelsen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.5s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.5s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.6s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.6s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.6s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.6s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.7s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.7s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.3s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.4s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.5s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.4s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.4s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.9s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   1.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   1.0s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   1.0s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.5s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.5s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   1.2s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.9s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.7s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   1.0s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.8s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.8s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.7s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.7s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.8s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.7s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.8s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.9s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.8s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.9s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.8s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.8s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.7s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.7s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.7s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.7s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.8s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.7s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.7s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.9s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.8s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.9s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.8s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.8s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   1.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.9s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.9s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.8s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.8s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.9s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.8s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.8s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.6s\n",
      "Best Parameters: {'C': 0.001, 'penalty': 'l2'}\n",
      "Best Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model with 'liblinear' solver\n",
    "logistic_regression = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Create a dictionary of all values you want to test for C and penalty\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # The norm used in the penalization\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best parameters\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model with your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[1353    0]\n",
      " [   0 1414]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1353\n",
      "           1       1.00      1.00      1.00      1414\n",
      "\n",
      "    accuracy                           1.00      2767\n",
      "   macro avg       1.00      1.00      1.00      2767\n",
      "weighted avg       1.00      1.00      1.00      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the best estimator to make predictions on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the evaluation results\n",
    "print('Accuracy:', accuracy)\n",
    "print('Confusion Matrix:\\n', conf_mat)\n",
    "print('Classification Report:\\n', report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
