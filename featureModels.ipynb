{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>TTR</th>\n",
       "      <th>text_polarity</th>\n",
       "      <th>text_subjectivity</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>doc_perplexity</th>\n",
       "      <th>1_grams</th>\n",
       "      <th>average_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.524184</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.867938</td>\n",
       "      <td>['donald', 'trump', 'met', 'member', 'nato', '...</td>\n",
       "      <td>6.490826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683438</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.343395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882860</td>\n",
       "      <td>['washington', 'reuters', 'rick', 'perry', 'pr...</td>\n",
       "      <td>6.385744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.721030</td>\n",
       "      <td>0.073622</td>\n",
       "      <td>0.401345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883760</td>\n",
       "      <td>['president', 'obama', 'blasted', 'republican'...</td>\n",
       "      <td>6.072961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.667638</td>\n",
       "      <td>0.037264</td>\n",
       "      <td>0.462935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882882</td>\n",
       "      <td>['male', 'idaho', 'republican', 'daughter', 'c...</td>\n",
       "      <td>6.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.628032</td>\n",
       "      <td>-0.018966</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.883120</td>\n",
       "      <td>['kellyanne', 'conway', 'tried', 'spin', 'whit...</td>\n",
       "      <td>6.296496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13829</th>\n",
       "      <td>0</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>-0.030698</td>\n",
       "      <td>0.380595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882810</td>\n",
       "      <td>['washington', 'reuters', 'member', 'congress'...</td>\n",
       "      <td>6.514512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13830</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629126</td>\n",
       "      <td>-0.009035</td>\n",
       "      <td>0.312617</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.895444</td>\n",
       "      <td>['far', 'video', '530000', 'view', 'make', 'co...</td>\n",
       "      <td>6.782524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13831</th>\n",
       "      <td>0</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.883645</td>\n",
       "      <td>['dec', '27', 'story', 'corrects', 'say', '550...</td>\n",
       "      <td>6.117021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13832</th>\n",
       "      <td>0</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>-0.026939</td>\n",
       "      <td>0.293520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.895276</td>\n",
       "      <td>['madrid', 'reuters', 'spain', 'high', 'court'...</td>\n",
       "      <td>6.478632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13833</th>\n",
       "      <td>1</td>\n",
       "      <td>0.719472</td>\n",
       "      <td>0.064587</td>\n",
       "      <td>0.499129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867533</td>\n",
       "      <td>['woman', 'fox', 'news', 'sick', 'tired', 'put...</td>\n",
       "      <td>6.102310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13834 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label       TTR  text_polarity  text_subjectivity  title_polarity  \\\n",
       "0          1  0.844037       0.091481           0.524184       -0.125000   \n",
       "1          0  0.683438       0.003001           0.343395        0.000000   \n",
       "2          1  0.721030       0.073622           0.401345        0.000000   \n",
       "3          1  0.667638       0.037264           0.462935        0.000000   \n",
       "4          1  0.628032      -0.018966           0.479310       -0.800000   \n",
       "...      ...       ...            ...                ...             ...   \n",
       "13829      0  0.659631      -0.030698           0.380595        0.000000   \n",
       "13830      1  0.629126      -0.009035           0.312617       -0.066667   \n",
       "13831      0  0.595745       0.049287           0.244648        0.000000   \n",
       "13832      0  0.696581      -0.026939           0.293520        0.000000   \n",
       "13833      1  0.719472       0.064587           0.499129        0.000000   \n",
       "\n",
       "       title_subjectivity  doc_perplexity  \\\n",
       "0                0.125000        0.867938   \n",
       "1                0.000000        0.882860   \n",
       "2                1.000000        0.883760   \n",
       "3                1.000000        0.882882   \n",
       "4                0.900000        0.883120   \n",
       "...                   ...             ...   \n",
       "13829            0.000000        0.882810   \n",
       "13830            0.633333        0.895444   \n",
       "13831            0.000000        0.883645   \n",
       "13832            0.000000        0.895276   \n",
       "13833            0.000000        0.867533   \n",
       "\n",
       "                                                 1_grams  average_word_length  \n",
       "0      ['donald', 'trump', 'met', 'member', 'nato', '...             6.490826  \n",
       "1      ['washington', 'reuters', 'rick', 'perry', 'pr...             6.385744  \n",
       "2      ['president', 'obama', 'blasted', 'republican'...             6.072961  \n",
       "3      ['male', 'idaho', 'republican', 'daughter', 'c...             6.469388  \n",
       "4      ['kellyanne', 'conway', 'tried', 'spin', 'whit...             6.296496  \n",
       "...                                                  ...                  ...  \n",
       "13829  ['washington', 'reuters', 'member', 'congress'...             6.514512  \n",
       "13830  ['far', 'video', '530000', 'view', 'make', 'co...             6.782524  \n",
       "13831  ['dec', '27', 'story', 'corrects', 'say', '550...             6.117021  \n",
       "13832  ['madrid', 'reuters', 'spain', 'high', 'court'...             6.478632  \n",
       "13833  ['woman', 'fox', 'news', 'sick', 'tired', 'put...             6.102310  \n",
       "\n",
       "[13834 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv('features_dataset.csv')\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                    int64\n",
       "TTR                    float64\n",
       "text_polarity          float64\n",
       "text_subjectivity      float64\n",
       "title_polarity         float64\n",
       "title_subjectivity     float64\n",
       "doc_perplexity         float64\n",
       "1_grams                 object\n",
       "average_word_length    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the datatypes to understand the different features\n",
    "features_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from above, 1_grams is not numerical, and therefore we need to convert it to numerical values to enable modelling with the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore start by cleaning the data, and then we seperate it into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizer to convert 1_grams to a fitting datatype\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorize text data\n",
    "X_vectorized = vectorizer.fit_transform(features_df['1_grams'])\n",
    "\n",
    "# Drop 1_grams column and convert df to a sparse DataFrame to concatenate with X_vectorized\n",
    "df_dropped = features_df.drop('1_grams', axis=1).astype(float) # Convert other columns to float\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "df_dropped_sparse = csr_matrix(df_dropped.values)  # Convert DataFrame to sparse matrix\n",
    "X_final = hstack([df_dropped_sparse, X_vectorized])  # Concatenate the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with negative values and their counts:\n",
      "text_polarity: 3097 negatives\n",
      "title_polarity: 3117 negatives\n"
     ]
    }
   ],
   "source": [
    "# We then convert columns to numeric and furthermore look for negative values as these also needs to be normalized\n",
    "def check_negatives(dataframe):\n",
    "    negative_counts = {}\n",
    "    for column in dataframe.columns:\n",
    "        # Convert column to numeric, non-convertible values become NaN\n",
    "        converted_column = pd.to_numeric(dataframe[column], errors='coerce')\n",
    "        # Count negative values\n",
    "        count = (converted_column < 0).sum()\n",
    "        if count > 0:\n",
    "            negative_counts[column] = count\n",
    "    return negative_counts\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "negative_columns = check_negatives(features_df)\n",
    "\n",
    "# Print the columns with negative values and their counts\n",
    "print(\"Columns with negative values and their counts:\")\n",
    "for column, count in negative_columns.items():\n",
    "    print(f\"{column}: {count} negatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_negatives_exclude_non_numeric(dataframe):\n",
    "    negative_counts = {}\n",
    "    for column in dataframe.columns:\n",
    "        # Attempt to convert column to numeric\n",
    "        converted_column = pd.to_numeric(dataframe[column], errors='coerce')\n",
    "        # Continue only if the column is numeric\n",
    "        if converted_column.dtype != 'object':\n",
    "            # Count negative values\n",
    "            count = (converted_column < 0).sum()\n",
    "            if count > 0:\n",
    "                negative_counts[column] = count\n",
    "    return negative_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all columns to numeric, handling non-numeric gracefully\n",
    "df = features_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values that result from conversion errors\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data to scale each feature to [0, 1] range\n",
    "df_scaled = scaler.fit_transform(df.drop('label', axis=1))\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_scaled\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6176364293458619\n",
      "Confusion Matrix:\n",
      " [[954 399]\n",
      " [659 755]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.64      1353\n",
      "           1       0.65      0.53      0.59      1414\n",
      "\n",
      "    accuracy                           0.62      2767\n",
      "   macro avg       0.62      0.62      0.62      2767\n",
      "weighted avg       0.62      0.62      0.62      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing the model using gridsearch to increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Best CV score: 0.72\n",
      "Test Accuracy: 0.7217202746657029\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      1353\n",
      "           1       0.76      0.67      0.71      1414\n",
      "\n",
      "    accuracy                           0.72      2767\n",
      "   macro avg       0.73      0.72      0.72      2767\n",
      "weighted avg       0.73      0.72      0.72      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Evaluate using the best parameters\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to vizualise the confusion matrix as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAIhCAYAAAD91lq9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf7klEQVR4nO3deZzNdf//8eeZ7czCDDOYMRqMJVkjSka2bMnWT1fCVJaxFNFkK7kKqRnmKhRFSYwtuhJXKkLJlaiGKCQtxpaZiLGPWT+/P3ydq2PGMh/nOMecx93tc7vmvD/v8zmvzyfT9er1Xo7FMAxDAAAAQBF5uToAAAAA3JxIJAEAAGAKiSQAAABMIZEEAACAKSSSAAAAMIVEEgAAAKaQSAIAAMAUEkkAAACYQiIJAAAAU0gkgZvAjz/+qL59+yo6Olr+/v4qUaKE7rjjDiUlJen48eNO/ext27apRYsWCgkJkcVi0bRp0xz+GRaLRePHj3f4da9m3rx5slgsslgs+vLLLwucNwxD1apVk8ViUcuWLU19xptvvql58+YV6T1ffvnlZWMCAHfi4+oAAFzZ7NmzNXjwYNWoUUOjRo1SrVq1lJOToy1btmjWrFnavHmzli9f7rTP79evn86ePaslS5aodOnSqly5ssM/Y/Pmzbrlllscft1rVbJkSc2ZM6dAsrhhwwb9/vvvKlmypOlrv/nmmypTpoz69Olzze+54447tHnzZtWqVcv05wLAjUAiCbixzZs364knnlDbtm21YsUKWa1W27m2bdtqxIgRWr16tVNj2LlzpwYMGKAOHTo47TPuvvtup137Wjz88MNatGiR3njjDQUHB9va58yZoyZNmujUqVM3JI6cnBxZLBYFBwe7/JkAwLVgaBtwYwkJCbJYLHr77bftksiL/Pz81KVLF9vr/Px8JSUl6bbbbpPValW5cuX02GOP6dChQ3bva9myperUqaOUlBQ1a9ZMgYGBqlKliiZNmqT8/HxJ/xv2zc3N1cyZM21DwJI0fvx4289/d/E9+/bts7V98cUXatmypcLCwhQQEKCKFSvqwQcf1Llz52x9Chva3rlzp7p27arSpUvL399f9evXV3Jysl2fi0PA7733nsaOHavIyEgFBwerTZs22rNnz7U9ZEk9e/aUJL333nu2tpMnT2rZsmXq169foe+ZMGGCGjdurNDQUAUHB+uOO+7QnDlzZBiGrU/lypW1a9cubdiwwfb8LlZ0L8a+YMECjRgxQhUqVJDVatVvv/1WYGj7r7/+UlRUlGJiYpSTk2O7/k8//aSgoCA9+uij13yvAOBIJJKAm8rLy9MXX3yhhg0bKioq6pre88QTT+iZZ55R27Zt9dFHH2nixIlavXq1YmJi9Ndff9n1TU9PV2xsrB555BF99NFH6tChg8aMGaOFCxdKkjp27KjNmzdLkv7xj39o8+bNttfXat++ferYsaP8/Pz07rvvavXq1Zo0aZKCgoKUnZ192fft2bNHMTEx2rVrl15//XV9+OGHqlWrlvr06aOkpKQC/Z977jnt379f77zzjt5++239+uuv6ty5s/Ly8q4pzuDgYP3jH//Qu+++a2t777335OXlpYcffviy9zZo0CC9//77+vDDD9WtWzcNHTpUEydOtPVZvny5qlSpogYNGtie36XTEMaMGaMDBw5o1qxZWrlypcqVK1fgs8qUKaMlS5YoJSVFzzzzjCTp3Llzeuihh1SxYkXNmjXrmu4TABzOAOCW0tPTDUlGjx49rqn/7t27DUnG4MGD7dq//fZbQ5Lx3HPP2dpatGhhSDK+/fZbu761atUy2rdvb9cmyRgyZIhd27hx44zC/vUxd+5cQ5KRmppqGIZhfPDBB4YkY/v27VeMXZIxbtw42+sePXoYVqvVOHDggF2/Dh06GIGBgcaJEycMwzCM9evXG5KM+++/367f+++/b0gyNm/efMXPvRhvSkqK7Vo7d+40DMMw7rzzTqNPnz6GYRhG7dq1jRYtWlz2Onl5eUZOTo7x4osvGmFhYUZ+fr7t3OXee/Hzmjdvftlz69evt2ufPHmyIclYvny50bt3byMgIMD48ccfr3iPAOBMVCSBYmL9+vWSVGBRx1133aWaNWvq888/t2uPiIjQXXfdZddWr1497d+/32Ex1a9fX35+fho4cKCSk5O1d+/ea3rfF198odatWxeoxPbp00fnzp0rUBn9+/C+dOE+JBXpXlq0aKGqVavq3Xff1Y4dO5SSknLZYe2LMbZp00YhISHy9vaWr6+vXnjhBR07dkxHjhy55s998MEHr7nvqFGj1LFjR/Xs2VPJycmaPn266tate83vBwBHI5EE3FSZMmUUGBio1NTUa+p/7NgxSVL58uULnIuMjLSdvygsLKxAP6vVqszMTBPRFq5q1apat26dypUrpyFDhqhq1aqqWrWqXnvttSu+79ixY5e9j4vn/+7Se7k4n7Qo92KxWNS3b18tXLhQs2bN0q233qpmzZoV2ve7775Tu3btJF1YVf/1118rJSVFY8eOLfLnFnafV4qxT58+On/+vCIiIpgbCcDlSCQBN+Xt7a3WrVtr69atBRbLFOZiMpWWllbg3OHDh1WmTBmHxebv7y9JysrKsmu/dB6mJDVr1kwrV67UyZMn9c0336hJkyaKj4/XkiVLLnv9sLCwy96HJIfey9/16dNHf/31l2bNmqW+fftett+SJUvk6+urjz/+WN27d1dMTIwaNWpk6jMLW7R0OWlpaRoyZIjq16+vY8eOaeTIkaY+EwAchUQScGNjxoyRYRgaMGBAoYtTcnJytHLlSknSvffeK0m2xTIXpaSkaPfu3WrdurXD4rq48vjHH3+0a78YS2G8vb3VuHFjvfHGG5Kk77///rJ9W7durS+++MKWOF40f/58BQYGOm1rnAoVKmjUqFHq3Lmzevfufdl+FotFPj4+8vb2trVlZmZqwYIFBfo6qsqbl5ennj17ymKxaNWqVUpMTNT06dP14YcfXve1AcAs9pEE3FiTJk00c+ZMDR48WA0bNtQTTzyh2rVrKycnR9u2bdPbb7+tOnXqqHPnzqpRo4YGDhyo6dOny8vLSx06dNC+ffv0/PPPKyoqSk8//bTD4rr//vsVGhqquLg4vfjii/Lx8dG8efN08OBBu36zZs3SF198oY4dO6pixYo6f/68bWV0mzZtLnv9cePG6eOPP1arVq30wgsvKDQ0VIsWLdInn3yipKQkhYSEOOxeLjVp0qSr9unYsaOmTJmiXr16aeDAgTp27JheeeWVQrdoqlu3rpYsWaKlS5eqSpUq8vf3NzWvcdy4cfrqq6+0Zs0aRUREaMSIEdqwYYPi4uLUoEEDRUdHF/maAHC9SCQBNzdgwADdddddmjp1qiZPnqz09HT5+vrq1ltvVa9evfTkk0/a+s6cOVNVq1bVnDlz9MYbbygkJET33XefEhMTC50TaVZwcLBWr16t+Ph4PfLIIypVqpT69++vDh06qH///rZ+9evX15o1azRu3Dilp6erRIkSqlOnjj766CPbHMPC1KhRQ5s2bdJzzz2nIUOGKDMzUzVr1tTcuXOL9A0xznLvvffq3Xff1eTJk9W5c2dVqFBBAwYMULly5RQXF2fXd8KECUpLS9OAAQN0+vRpVapUyW6fzWuxdu1aJSYm6vnnn7erLM+bN08NGjTQww8/rI0bN8rPz88RtwcA18xiGH/bPRcAAAC4RsyRBAAAgCkkkgAAADCFRBIAAACmkEgCAADAFBJJAAAAmEIiCQAAAFNIJAEAAGBKsdyQPKDBk1fvBOCmlJEyw9UhAHASfxdmJc7MHTK3Fd9/b1GRBAAAgCnFsiIJAABQJBZqa2aQSAIAAFgsro7gpkT6DQAAAFOoSAIAADC0bQpPDQAAAKZQkQQAAGCOpClUJAEAAGAKFUkAAADmSJrCUwMAAIApVCQBAACYI2kKiSQAAABD26bw1AAAAGAKFUkAAACGtk2hIgkAAABTqEgCAAAwR9IUnhoAAABMoSIJAADAHElTqEgCAADAFCqSAAAAzJE0hUQSAACAoW1TSL8BAABgChVJAAAAhrZN4akBAADAFCqSAAAAVCRN4akBAADAFCqSAAAAXqzaNoOKJAAAAEwhkQQAALB4Oe8oov/+97/q3LmzIiMjZbFYtGLFCrvzhmFo/PjxioyMVEBAgFq2bKldu3bZ9cnKytLQoUNVpkwZBQUFqUuXLjp06JBdn4yMDD366KMKCQlRSEiIHn30UZ04caJIsZJIAgAAWCzOO4ro7Nmzuv322zVjxoxCzyclJWnKlCmaMWOGUlJSFBERobZt2+r06dO2PvHx8Vq+fLmWLFmijRs36syZM+rUqZPy8vJsfXr16qXt27dr9erVWr16tbZv365HH320aI/NMAyjyHfo5gIaPOnqEAA4SUZK4f9iBXDz83fhyo2A1glOu3bm58+Zfq/FYtHy5cv1wAMPSLpQjYyMjFR8fLyeeeYZSReqj+Hh4Zo8ebIGDRqkkydPqmzZslqwYIEefvhhSdLhw4cVFRWlTz/9VO3bt9fu3btVq1YtffPNN2rcuLEk6ZtvvlGTJk30888/q0aNGtcUHxVJAAAAJw5tZ2Vl6dSpU3ZHVlaWqTBTU1OVnp6udu3a2dqsVqtatGihTZs2SZK2bt2qnJwcuz6RkZGqU6eOrc/mzZsVEhJiSyIl6e6771ZISIitz7UgkQQAAHCixMRE2zzEi0diYqKpa6Wnp0uSwsPD7drDw8Nt59LT0+Xn56fSpUtfsU+5cuUKXL9cuXK2PteC7X8AAABMzGW8VmPGjNHw4cPt2qxW63Vd03JJvIZhFGi71KV9Cut/Ldf5OyqSAAAATmS1WhUcHGx3mE0kIyIiJKlA1fDIkSO2KmVERISys7OVkZFxxT5//vlngesfPXq0QLXzSkgkAQAA3Gj7nyuJjo5WRESE1q5da2vLzs7Whg0bFBMTI0lq2LChfH197fqkpaVp586dtj5NmjTRyZMn9d1339n6fPvttzp58qStz7VgaBsAAMCNnDlzRr/99pvtdWpqqrZv367Q0FBVrFhR8fHxSkhIUPXq1VW9enUlJCQoMDBQvXr1kiSFhIQoLi5OI0aMUFhYmEJDQzVy5EjVrVtXbdq0kSTVrFlT9913nwYMGKC33npLkjRw4EB16tTpmldsSySSAAAATp0jWVRbtmxRq1atbK8vzq/s3bu35s2bp9GjRyszM1ODBw9WRkaGGjdurDVr1qhkyZK290ydOlU+Pj7q3r27MjMz1bp1a82bN0/e3t62PosWLdKwYcNsq7u7dOly2b0rL4d9JAHcVNhHEii+XLqP5H1TnHbtzNXDr97pJsUcSQAAAJjC0DYAAIAbDW3fTKhIAgAAwBQqkgAAAA7epsdT8NQAAABgChVJAAAA5kiaQkUSAAAAplCRBAAAYI6kKSSSAAAAJJKm8NQAAABgChVJAAAAFtuYQkUSAAAAplCRBAAAYI6kKTw1AAAAmEJFEgAAgDmSplCRBAAAgClUJAEAAJgjaQqJJAAAAEPbppB+AwAAwBQqkgAAwONZqEiaQkUSAAAAplCRBAAAHo+KpDlUJAEAAGAKFUkAAAAKkqZQkQQAAIApVCQBAIDHY46kOSSSAADA45FImsPQNgAAAEyhIgkAADweFUlzqEgCAADAFCqSAADA41GRNIeKJAAAAEyhIgkAAEBB0hQqkgAAADCFiiQAAPB4zJE0h4okAAAATKEiCQAAPB4VSXNIJAEAgMcjkTSHoW0AAACYQkUSAAB4PCqS5lCRBAAAgClUJAEAAChImkJFEgAAAKZQkQQAAB6POZLmUJEEAACAKVQkAQCAx6MiaQ6JJAAA8HgkkuYwtA0AAABT3CaR/Oqrr/TII4+oSZMm+uOPPyRJCxYs0MaNG10cGQAAKPYsTjyKMbdIJJctW6b27dsrICBA27ZtU1ZWliTp9OnTSkhIcHF0AAAAKIxbJJIvvfSSZs2apdmzZ8vX19fWHhMTo++//96FkQEAAE9gsVicdhTV6dOnFR8fr0qVKikgIEAxMTFKSUmxnTcMQ+PHj1dkZKQCAgLUsmVL7dq1y+4aWVlZGjp0qMqUKaOgoCB16dJFhw4duu7ndCm3SCT37Nmj5s2bF2gPDg7WiRMnbnxAAAAALtK/f3+tXbtWCxYs0I4dO9SuXTu1adPGNvUvKSlJU6ZM0YwZM5SSkqKIiAi1bdtWp0+ftl0jPj5ey5cv15IlS7Rx40adOXNGnTp1Ul5enkNjdYtEsnz58vrtt98KtG/cuFFVqlRxQUQAAMCTuEtFMjMzU8uWLVNSUpKaN2+uatWqafz48YqOjtbMmTNlGIamTZumsWPHqlu3bqpTp46Sk5N17tw5LV68WJJ08uRJzZkzR6+++qratGmjBg0aaOHChdqxY4fWrVvn0OfmFonkoEGD9NRTT+nbb7+VxWLR4cOHtWjRIo0cOVKDBw92dXgAAACmZWVl6dSpU3bHxfUgl8rNzVVeXp78/f3t2gMCArRx40alpqYqPT1d7dq1s52zWq1q0aKFNm3aJEnaunWrcnJy7PpERkaqTp06tj6O4haJ5OjRo/XAAw+oVatWOnPmjJo3b67+/ftr0KBBevLJJ10dHgAAKOacWZFMTExUSEiI3ZGYmFhoHCVLllSTJk00ceJEHT58WHl5eVq4cKG+/fZbpaWlKT09XZIUHh5u977w8HDbufT0dPn5+al06dKX7eMobrMh+csvv6yxY8fqp59+Un5+vmrVqqUSJUq4OiwAAOABnLkh+ZgxYzR8+HC7NqvVetn+CxYsUL9+/VShQgV5e3vrjjvuUK9evewWIF8ar2EYV72Ha+lTVG5RkUxOTtbZs2cVGBioRo0a6a677iKJBAAAxYLValVwcLDdcaVEsmrVqtqwYYPOnDmjgwcP6rvvvlNOTo6io6MVEREhSQUqi0eOHLFVKSMiIpSdna2MjIzL9nEUt0gkR44cqXLlyqlHjx76+OOPlZub6+qQAACAJ3HDDcmDgoJUvnx5ZWRk6LPPPlPXrl1tyeTatWtt/bKzs7VhwwbFxMRIkho2bChfX1+7Pmlpadq5c6etj6O4RSKZlpampUuXytvbWz169FD58uU1ePBgh08IBQAAcHefffaZVq9erdTUVK1du1atWrVSjRo11LdvX1ksFsXHxyshIUHLly/Xzp071adPHwUGBqpXr16SpJCQEMXFxWnEiBH6/PPPtW3bNj3yyCOqW7eu2rRp49BY3WKOpI+Pjzp16qROnTrp3LlzWr58uRYvXqxWrVrplltu0e+//+7qEAEAQDHmzDmSRXXy5EmNGTNGhw4dUmhoqB588EG9/PLLti9tGT16tDIzMzV48GBlZGSocePGWrNmjUqWLGm7xtSpU+Xj46Pu3bsrMzNTrVu31rx58+Tt7e3QWC2GYRgOvaID/PXXX1qyZIlmzZql3bt3F3nzzIAGrPQGiquMlBmuDgGAk/i7sLxV4YnlTrv2HzP/n9Ou7WpuUZGUZKtELlq0SOvWrVNUVJR69uypf//7364ODQAAFHPuVJG8mbhFItmzZ0+tXLlSgYGBeuihh/Tll186fDIoAAAAHMstEkmLxaKlS5eqffv28vFxi5AAAIAHoSJpjltkbRe/GxIAAMAlyCNNcVki+frrr2vgwIHy9/fX66+/fsW+w4YNu0FRAQAA4Fq5bNV2dHS0tmzZorCwMEVHR1+2n8Vi0d69e4t0bVZtA8UXq7aB4suVq7YrDv3Iadc+ML2L067tai77R5aamlrozwAAALg5uMU327z44os6d+5cgfbMzEy9+OKLLogIAAB4EovF4rSjOHOLRHLChAk6c+ZMgfZz585pwoQJLogIAAAAV+MWq7YNwyg0Y//hhx8UGhrqgohwIzW9o6qefqyN7qhVUeXLhqj7029r5Zc/2vUZO+h+xT3YVKVKBihl537FJy7V7r3ptvOfzX5KzRtVt3vPvz/bqseenVvg8/x8ffTfBSN1e41b1PjhRP34yx/OuTEABcyZ/ZY+X7tGqal7ZfX3V/36DRQ/fKQqR1ex9Tn211+aNuUVbd60UadPn9YdDRvp2bHPq1KlyrY+Bw8c0KuvTNb277cqOztbTe9ppmefe15hZcq44K5QHBT3yqGzuLQiWbp0aYWGhspisejWW29VaGio7QgJCVHbtm3VvXt3V4aIGyAowKodv/yhpye9X+j5EX3aaNgjrfT0pPd1zyP/0p/HTumTWUNVItBq12/Osq9Vuc0Y2/HkS+8Ver2E+K5KO3rS4fcB4Oq2pHynh3vGasF77+ut2XOVm5enxwfE2aY3GYah+GFDdOjQQU2b/qaWfrBc5SMraFBcX1ufc+fO6fGB/WSxWDT73WQlL3xPOTk5GjrkceXn57vy9gCP49KK5LRp02QYhvr166cJEyYoJCTEds7Pz0+VK1dWkyZNXBghboQ1X/+kNV//dNnzQ3q1UtKcz/SfL36QJPV/foH2f56ghzs00pxlX9v6ZZ7P1p/HTl/xs9o1raXWd9dUz1Hv6L57ajvmBgBcs5lvz7F7/eJLiWrVrIl2/7RLDRvdqf379+nHH7Zr2X8+VrVqF0YZxj4/Tq2axWj1p5+o2z8e0vZt3+vwH39o6QcrVKJECdt1msXcpe++/UZ3N+Gb0VB0VCTNcWki2bt3b0kXtgKKiYmRr6+vK8OBG6pcIUzly4Zo3eafbW3ZObn6autvuvv2KnaJ5MP3N1KP++/UkeOntebrn/TyW5/qzLks2/lyoSX15vM91X34bJ3LzL6h9wGgcGdOX/iPv+D/KyTkZF/43bT6/W/EwdvbW76+vtr2/VZ1+8dDys7OlsVikZ+fn62Pn9UqLy8vbft+K4kkzCGPNMUt5ki2aNHC9nNmZqZycnLszgcHB1/2vVlZWcrKyrJrM/LzZPHydmyQcImIMhf+2R85bl9pPHLstCqW/9/82SWfpmjf4WP6869Tql0tUi8O7ay6t1ZQpyf+t+fg2y8+otkfbNT3Px2wey8A1zAMQ68kJarBHQ1VvfqtkqTK0VUUGVlBr097Vc+Pe1EBAQGanzxPf/11VEePHpUk1bu9vgICAjTt1X9paPxwGYahaVNeUX5+vq0PgBvDLVZtnzt3Tk8++aTKlSunEiVKqHTp0nbHlSQmJiokJMTuyP1z6w2KHDfKpfvmWyz2bXOXb9L6b/fop9/T9O/PtqrXqDlqffdtqn/bLZKkwT1bKDjIX/96d80NjRvA5SW+9KJ+/eUXTf7XFFubr6+vXp32uvbv26dmMXepcaP62pLyre5p1lze3hf+Lys0NFT/mvKaNmxYryZ3NtA9dzfSmTOnVbNWbXl7ucX/reEmxPY/5rhFRXLUqFFav3693nzzTT322GN644039Mcff+itt97SpEmTrvjeMWPGaPjw4XZt5Zo948xwcQOl/3VKkhQeFmz7WZLKhpYsUKX8u227Dyo7J1fVKpbT9p8PqeWdt+quutE6+e00u35fLxqtJau2aMALC5wSP4DCJb48UV9++YXeTV6o8IgIu3O1atfR+x/+R6dPn1ZOTo5CQ0MV2+Mh1a5dx9Ynpuk9+mT1OmVkHJe3t4+Cg4N1b/OmqtDhlht9K4BHc4tEcuXKlZo/f75atmypfv36qVmzZqpWrZoqVaqkRYsWKTY29rLvtVqtslrtV+8yrF187PvjmNKOnlTru2/TD3sOSZJ8fbzVrGE1/fO1/1z2fbWqlpefr4/S/rqwOntE0gca/8bHtvPly4bo45lP6tFn5yplxz6n3gOA/zEMQ4kvT9QXn6/VnHkLdMstUZftW7JkSUnS/v379NOunRoy9KkCfUqXvjBN5dtvNuv48WNq2epe5wSOYq+4Vw6dxS0SyePHj9u+bzs4OFjHjx+XJN1zzz164oknXBkaboCgAD9VjSpre125Qpjq3VpBGafO6WB6ht5YvF6j4trptwNH9NuBoxod116Z53O0dNUWSVL0LWXU4/5G+mzjT/or44xqVo3QpKe7advug9q8/cL3tB9Mz7D7zIuLcPYePKo/jpy4MTcKQAkTJ2jVpx9r2vQ3FRQYpL/+b05jiZIl5e/vL0la89kqlS4dqvLlI/Xrr3uUlJigVve2UUzTe2zXWbF8mapUqarSpUP1ww/blJSYoEce62O3HyUA53OLRLJKlSrat2+fKlWqpFq1aun999/XXXfdpZUrV6pUqVKuDg9OdketSlrzzv8qDUkjH5QkLfjoGw0ct1Cvzlsnf6ufpo15WKWDA5Wyc586PTHDlgzm5OSq1V01NKRnK5UI9NOh9BNavXGnXn5rlfLzjUI/E4BrvL/0wv6ucX0etWt/8aVEdf1/3SRJR48e1StJk3Tsr2MqW7asOnXpqkGPD7brvy81Va9PnaKTJ08qskIF9R/4uB7t3eeG3AOKJwqS5liMS1cxuMDUqVPl7e2tYcOGaf369erYsaPy8vKUm5urKVOm6KmnCg5nXElAgyedFCkAV8tImXH1TgBuSv4uLG9VG7nKadf+7ZUOTru2q7lFRfLpp5+2/dyqVSv9/PPP2rJli6pWrarbb7/dhZEBAABPwBxJc9wikbxUxYoVVbFiRVeHAQAAPAR5pDlukUi+/vrrhbZbLBb5+/urWrVqat68uby9WY0NAADgLtwikZw6daqOHj2qc+fOqXTp0jIMQydOnFBgYKBKlCihI0eOqEqVKlq/fr2ioi6/VQQAAIAZDG2b4xZfAZCQkKA777xTv/76q44dO6bjx4/rl19+UePGjfXaa6/pwIEDioiIsJtLCQAAANdyi4rkP//5Ty1btkxVq1a1tVWrVk2vvPKKHnzwQe3du1dJSUl68MEHXRglAAAorihImuMWFcm0tDTl5uYWaM/NzVV6erokKTIyUqdPX/4r8QAAAHBjuUUi2apVKw0aNEjbtm2ztW3btk1PPPGE7r33wtdd7dixw/btNwAAAI7k5WVx2lGcuUUiOWfOHIWGhqphw4a2785u1KiRQkNDNWfOHElSiRIl9Oqrr7o4UgAAAFzkFnMkIyIitHbtWv3888/65ZdfZBiGbrvtNtWoUcPWp1WrVi6MEAAAFGfMkTTHLRLJi6pUqSKLxaKqVavKx8etQgMAAMUY2/+Y4xZD2+fOnVNcXJwCAwNVu3ZtHThwQJI0bNgwTZo0ycXRAQAAoDBukUiOGTNGP/zwg7788kv5+/vb2tu0aaOlS5e6MDIAAOAJLBbnHcWZW4wfr1ixQkuXLtXdd99tV1quVauWfv/9dxdGBgAAgMtxi0Ty6NGjKleuXIH2s2fPMmcBAAA4HfmGOW4xtH3nnXfqk08+sb2++A9z9uzZatKkiavCAgAAwBW4RUUyMTFR9913n3766Sfl5ubqtdde065du7R582Zt2LDB1eEBAIBijoqkOW5RkYyJidHXX3+tc+fOqWrVqlqzZo3Cw8O1efNmNWzY0NXhAQAAoBBuUZGUpLp16yo5OdnVYQAAAA9EQdIclyaSXl5eVy0lWywW5ebm3qCIAACAJ2Jo2xyXJpLLly+/7LlNmzZp+vTpMgzjBkYEAACAa+XSRLJr164F2n7++WeNGTNGK1euVGxsrCZOnOiCyAAAgCehIGmOWyy2kaTDhw9rwIABqlevnnJzc7V9+3YlJyerYsWKrg4NAAAAhXD5YpuTJ08qISFB06dPV/369fX555+rWbNmrg4LAAB4EOZImuPSRDIpKUmTJ09WRESE3nvvvUKHugEAAOCeXJpIPvvsswoICFC1atWUnJx82e1/PvzwwxscGQAA8CQUJM1xaSL52GOPUUoGAAC4Sbk0kZw3b54rPx4AAEAScyTNcptV2wAAALi5uHzVNgAAgKtRkDSHiiQAAPB4FovFaUdR5Obm6p///Keio6MVEBCgKlWq6MUXX1R+fr6tj2EYGj9+vCIjIxUQEKCWLVtq165ddtfJysrS0KFDVaZMGQUFBalLly46dOiQQ57V35FIAgAAuInJkydr1qxZmjFjhnbv3q2kpCT961//0vTp0219kpKSNGXKFM2YMUMpKSmKiIhQ27Ztdfr0aVuf+Ph4LV++XEuWLNHGjRt15swZderUSXl5eQ6Nl6FtAADg8dxlaHvz5s3q2rWrOnbsKEmqXLmy3nvvPW3ZskXShWrktGnTNHbsWHXr1k2SlJycrPDwcC1evFiDBg3SyZMnNWfOHC1YsEBt2rSRJC1cuFBRUVFat26d2rdv77B4qUgCAAA4UVZWlk6dOmV3ZGVlFdr3nnvu0eeff65ffvlFkvTDDz9o48aNuv/++yVJqampSk9PV7t27WzvsVqtatGihTZt2iRJ2rp1q3Jycuz6REZGqk6dOrY+jkIiCQAAPJ4z50gmJiYqJCTE7khMTCw0jmeeeUY9e/bUbbfdJl9fXzVo0EDx8fHq2bOnJCk9PV2SFB4ebve+8PBw27n09HT5+fmpdOnSl+3jKAxtAwAAONGYMWM0fPhwuzar1Vpo36VLl2rhwoVavHixateure3btys+Pl6RkZHq3bu3rd+li3gMw7jqwp5r6VNUJJIAAMDjOXOOpNVqvWzieKlRo0bp2WefVY8ePSRJdevW1f79+5WYmKjevXsrIiJC0oWqY/ny5W3vO3LkiK1KGRERoezsbGVkZNhVJY8cOaKYmBhH3ZYkhrYBAADcxrlz5+TlZZ+eeXt727b/iY6OVkREhNauXWs7n52drQ0bNtiSxIYNG8rX19euT1pamnbu3OnwRJKKJAAA8Hju8hWJnTt31ssvv6yKFSuqdu3a2rZtm6ZMmaJ+/fpJuhBnfHy8EhISVL16dVWvXl0JCQkKDAxUr169JEkhISGKi4vTiBEjFBYWptDQUI0cOVJ169a1reJ2FBJJAADg8dwkj9T06dP1/PPPa/DgwTpy5IgiIyM1aNAgvfDCC7Y+o0ePVmZmpgYPHqyMjAw1btxYa9asUcmSJW19pk6dKh8fH3Xv3l2ZmZlq3bq15s2bJ29vb4fGazEMw3DoFd1AQIMnXR0CACfJSJnh6hAAOIm/C8tb97zyldOuvXFkM6dd29WoSAIAAI/nLkPbNxsW2wAAAMAUKpIAAMDjUZE0h4okAAAATKEiCQAAPB4FSXOoSAIAAMAUKpIAAMDjMUfSHBJJAADg8cgjzWFoGwAAAKZQkQQAAB6PoW1zqEgCAADAFCqSAADA41GQNIeKJAAAAEyhIgkAADyeFyVJU6hIAgAAwBQqkgAAwONRkDSHRBIAAHg8tv8xh6FtAAAAmEJFEgAAeDwvCpKmUJEEAACAKVQkAQCAx2OOpDlUJAEAAGAKFUkAAODxKEiaQ0USAAAAplCRBAAAHs8iSpJmkEgCAACPx/Y/5jC0DQAAAFOoSAIAAI/H9j/mUJEEAACAKVQkAQCAx6MgaQ4VSQAAAJjikIrkiRMnVKpUKUdcCgAA4IbzoiRpSpErkpMnT9bSpUttr7t3766wsDBVqFBBP/zwg0ODAwAAgPsqciL51ltvKSoqSpK0du1arV27VqtWrVKHDh00atQohwcIAADgbBaL847irMhD22lpabZE8uOPP1b37t3Vrl07Va5cWY0bN3Z4gAAAAM7G9j/mFLkiWbp0aR08eFCStHr1arVp00aSZBiG8vLyHBsdAAAA3FaRK5LdunVTr169VL16dR07dkwdOnSQJG3fvl3VqlVzeIAAAADORkHSnCInklOnTlXlypV18OBBJSUlqUSJEpIuDHkPHjzY4QECAADAPRU5kfT19dXIkSMLtMfHxzsiHgAAgBuO7X/MuaZE8qOPPrrmC3bp0sV0MAAAALh5XFMi+cADD1zTxSwWCwtuAADATYd6pDnXlEjm5+c7Ow4AAADcZK7rKxLPnz8vf39/R8UCAADgEuwjaU6R95HMy8vTxIkTVaFCBZUoUUJ79+6VJD3//POaM2eOwwMEAABwNi+L847irMiJ5Msvv6x58+YpKSlJfn5+tva6devqnXfecWhwAAAAcF9FTiTnz5+vt99+W7GxsfL29ra116tXTz///LNDgwMAALgRLBaL047irMiJ5B9//FHoN9jk5+crJyfHIUEBAADA/RU5kaxdu7a++uqrAu3//ve/1aBBA4cEBQAAcCNZLM47irMir9oeN26cHn30Uf3xxx/Kz8/Xhx9+qD179mj+/Pn6+OOPnREjAAAA3FCRK5KdO3fW0qVL9emnn8piseiFF17Q7t27tXLlSrVt29YZMQIAADgVcyTNKXIiKUnt27fXhg0bdObMGZ07d04bN25Uu3btHB0bAACAR6lcuXKhyeiQIUMkSYZhaPz48YqMjFRAQIBatmypXbt22V0jKytLQ4cOVZkyZRQUFKQuXbro0KFDTonXVCIpSVu2bNGCBQu0cOFCbd261ZExAQAA3FDuso9kSkqK0tLSbMfatWslSQ899JAkKSkpSVOmTNGMGTOUkpKiiIgItW3bVqdPn7ZdIz4+XsuXL9eSJUu0ceNGnTlzRp06dXLK11gXeY7koUOH1LNnT3399dcqVaqUJOnEiROKiYnRe++9p6ioKEfHCAAA4FTuMgRdtmxZu9eTJk1S1apV1aJFCxmGoWnTpmns2LHq1q2bJCk5OVnh4eFavHixBg0apJMnT2rOnDlasGCB2rRpI0lauHChoqKitG7dOrVv396h8Ra5ItmvXz/l5ORo9+7dOn78uI4fP67du3fLMAzFxcU5NDgAAICbXVZWlk6dOmV3ZGVlXfV92dnZWrhwofr16yeLxaLU1FSlp6fbTSe0Wq1q0aKFNm3aJEnaunWrcnJy7PpERkaqTp06tj6OVORE8quvvtLMmTNVo0YNW1uNGjU0ffr0QrcFAgAAcHcWJx6JiYkKCQmxOxITE68a04oVK3TixAn16dNHkpSeni5JCg8Pt+sXHh5uO5eeni4/Pz+VLl36sn0cqchD2xUrVix04/Hc3FxVqFDBIUEBAAAUF2PGjNHw4cPt2qxW61XfN2fOHHXo0EGRkZF27ZcOwxuGcdWh+WvpY0aRK5JJSUkaOnSotmzZIsMwJF1YePPUU0/plVdecXiAAAAAzuZlsTjtsFqtCg4Otjuulkju379f69atU//+/W1tERERklSgsnjkyBFblTIiIkLZ2dnKyMi4bB9HuqZEsnTp0goNDVVoaKj69u2r7du3q3HjxvL395fValXjxo31/fffq1+/fg4PEAAAwNPMnTtX5cqVU8eOHW1t0dHRioiIsK3kli7Mo9ywYYNiYmIkSQ0bNpSvr69dn7S0NO3cudPWx5GuaWh72rRpDv9gAAAAd+Emi7YlSfn5+Zo7d6569+4tH5//pWoWi0Xx8fFKSEhQ9erVVb16dSUkJCgwMFC9evWSJIWEhCguLk4jRoxQWFiYQkNDNXLkSNWtW9e2ituRrimR7N27t8M/GAAAAAWtW7dOBw4cKHSkd/To0crMzNTgwYOVkZGhxo0ba82aNSpZsqStz9SpU+Xj46Pu3bsrMzNTrVu31rx58+Tt7e3wWC3GxYmOJmRmZhZYeBMcHHzdQV2vgAZPujoEAE6SkTLD1SEAcBL/Ii8BdpyB/9519U4mvf1Qbadd29WKvNjm7NmzevLJJ1WuXDmVKFFCpUuXtjsAAADgGYqcSI4ePVpffPGF3nzzTVmtVr3zzjuaMGGCIiMjNX/+fGfECAAA4FQWi/OO4qzIReSVK1dq/vz5atmypfr166dmzZqpWrVqqlSpkhYtWqTY2FhnxAkAAOA0XsU943OSIlckjx8/rujoaEkX5kMeP35cknTPPffov//9r2OjAwAAgNsqciJZpUoV7du3T5JUq1Ytvf/++5IuVCpLlSrlyNgAAABuCIa2zSlyItm3b1/98MMPki585c/FuZJPP/20Ro0a5fAAAQAA4J6KPEfy6aeftv3cqlUr/fzzz9qyZYuqVq2q22+/3aHBAQAA3AjO+B5qT1DkiuSlKlasqG7duik0NJSvSAQAAPAgDtv68/jx40pOTta7777rqEua9t8PX3Z1CACcpGxssqtDAOAkp5e67pv0rruy5qF4bgAAADDFhV9GBAAA4B6YI2kOiSQAAPB4XuSRplxzItmtW7crnj9x4sT1xgIAAICbyDUnkiEhIVc9/9hjj113QAAAADcaFUlzrjmRnDt3rjPjAAAAwE2GOZIAAMDjsdjGHLb/AQAAgClUJAEAgMdjjqQ5VCQBAABgChVJAADg8ZgiaY6piuSCBQvUtGlTRUZGav/+/ZKkadOm6T//+Y9DgwMAALgRvCwWpx3FWZETyZkzZ2r48OG6//77deLECeXl5UmSSpUqpWnTpjk6PgAAALipIieS06dP1+zZszV27Fh5e3vb2hs1aqQdO3Y4NDgAAIAbwcuJR3FW5PtLTU1VgwYNCrRbrVadPXvWIUEBAADA/RU5kYyOjtb27dsLtK9atUq1atVyREwAAAA3lMXivKM4K/Kq7VGjRmnIkCE6f/68DMPQd999p/fee0+JiYl65513nBEjAAAA3FCRE8m+ffsqNzdXo0eP1rlz59SrVy9VqFBBr732mnr06OGMGAEAAJyquK+udhZT+0gOGDBAAwYM0F9//aX8/HyVK1fO0XEBAADAzV3XhuRlypRxVBwAAAAuQ0HSnCInktHR0bJc4Wnv3bv3ugICAAC40fiubXOKnEjGx8fbvc7JydG2bdu0evVqjRo1ylFxAQAAwM0VOZF86qmnCm1/4403tGXLlusOCAAA4EZjsY05DttwvUOHDlq2bJmjLgcAAAA3d12Lbf7ugw8+UGhoqKMuBwAAcMNQkDSnyIlkgwYN7BbbGIah9PR0HT16VG+++aZDgwMAAID7KnIi+cADD9i99vLyUtmyZdWyZUvddtttjooLAADghmHVtjlFSiRzc3NVuXJltW/fXhEREc6KCQAAADeBIi228fHx0RNPPKGsrCxnxQMAAHDDWZz4pzgr8qrtxo0ba9u2bc6IBQAAwCW8LM47irMiz5EcPHiwRowYoUOHDqlhw4YKCgqyO1+vXj2HBQcAAAD3dc2JZL9+/TRt2jQ9/PDDkqRhw4bZzlksFhmGIYvFory8PMdHCQAA4ETFvXLoLNecSCYnJ2vSpElKTU11ZjwAAAC4SVxzImkYhiSpUqVKTgsGAADAFSzsSG5KkRbb8JABAABwUZEW29x6661XTSaPHz9+XQEBAADcaMyRNKdIieSECRMUEhLirFgAAABwEylSItmjRw+VK1fOWbEAAAC4BLP3zLnmRJL5kQAAoLjyIs8x5ZoX21xctQ0AAABIRahI5ufnOzMOAAAAl2GxjTlF/q5tAAAAQCKRBAAAkMXivKOo/vjjDz3yyCMKCwtTYGCg6tevr61bt9rOG4ah8ePHKzIyUgEBAWrZsqV27dpld42srCwNHTpUZcqUUVBQkLp06aJDhw5d72MqgEQSAADATWRkZKhp06by9fXVqlWr9NNPP+nVV19VqVKlbH2SkpI0ZcoUzZgxQykpKYqIiFDbtm11+vRpW5/4+HgtX75cS5Ys0caNG3XmzBl16tRJeXl5Do23SNv/AAAAFEdeco9JkpMnT1ZUVJTmzp1ra6tcubLtZ8MwNG3aNI0dO1bdunWTJCUnJys8PFyLFy/WoEGDdPLkSc2ZM0cLFixQmzZtJEkLFy5UVFSU1q1bp/bt2zssXiqSAAAATpSVlaVTp07ZHVlZWYX2/eijj9SoUSM99NBDKleunBo0aKDZs2fbzqempio9PV3t2rWztVmtVrVo0UKbNm2SJG3dulU5OTl2fSIjI1WnTh1bH0chkQQAAB7PmXMkExMTFRISYnckJiYWGsfevXs1c+ZMVa9eXZ999pkef/xxDRs2TPPnz5ckpaenS5LCw8Pt3hceHm47l56eLj8/P5UuXfqyfRyFoW0AAODxnLn9z5gxYzR8+HC7NqvVWmjf/Px8NWrUSAkJCZKkBg0aaNeuXZo5c6Yee+wxW79LvyjGMIyrfnnMtfQpKiqSAAAATmS1WhUcHGx3XC6RLF++vGrVqmXXVrNmTR04cECSFBERIUkFKotHjhyxVSkjIiKUnZ2tjIyMy/ZxFBJJAADg8bwsFqcdRdG0aVPt2bPHru2XX35RpUqVJEnR0dGKiIjQ2rVrbeezs7O1YcMGxcTESJIaNmwoX19fuz5paWnauXOnrY+jMLQNAADgJp5++mnFxMQoISFB3bt313fffae3335bb7/9tqQLQ9rx8fFKSEhQ9erVVb16dSUkJCgwMFC9evWSJIWEhCguLk4jRoxQWFiYQkNDNXLkSNWtW9e2ittRSCQBAIDHc/DUQdPuvPNOLV++XGPGjNGLL76o6OhoTZs2TbGxsbY+o0ePVmZmpgYPHqyMjAw1btxYa9asUcmSJW19pk6dKh8fH3Xv3l2ZmZlq3bq15s2bJ29vb4fGazEMw3DoFd1ASupJV4cAwEnufXaFq0MA4CSnl/Z22WfP/na/0649oHElp13b1ahIAgAAj1fUuYy4gMU2AAAAMIWKJAAA8HgUJM0hkQQAAB6PIVpzeG4AAAAwhYokAADweI7+6kBPQUUSAAAAplCRBAAAHo96pDlUJAEAAGAKFUkAAODx2JDcHCqSAAAAMIWKJAAA8HjUI80hkQQAAB6PkW1zGNoGAACAKVQkAQCAx2NDcnOoSAIAAMAUKpIAAMDjUVkzh+cGAAAAU6hIAgAAj8ccSXOoSAIAAMAUKpIAAMDjUY80h4okAAAATKEiCQAAPB5zJM0hkQQAAB6PIVpzeG4AAAAwhYokAADweAxtm0NFEgAAAKZQkQQAAB6PeqQ5VCQBAABgChVJAADg8ZgiaQ4VSQAAAJhCRRIAAHg8L2ZJmkIiCQAAPB5D2+YwtA0AAABTqEgCAACPZ2Fo2xQqkgAAADCFiiQAAPB4zJE0h4okAAAATKEiCQAAPB7b/5jjNhXJBQsWqGnTpoqMjNT+/fslSdOmTdN//vMfF0cGAACAwrhFIjlz5kwNHz5c999/v06cOKG8vDxJUqlSpTRt2jTXBgcAAIo9i8V5R3HmFonk9OnTNXv2bI0dO1be3t629kaNGmnHjh0ujAwAAHgCEklz3CKRTE1NVYMGDQq0W61WnT171gURAQAA4GrcIpGMjo7W9u3bC7SvWrVKtWrVuvEBAQAAj2Jx4p/izC1WbY8aNUpDhgzR+fPnZRiGvvvuO7333ntKTEzUO++84+rwAAAAUAi3SCT79u2r3NxcjR49WufOnVOvXr1UoUIFvfbaa+rRo4erwwMAAMWcV/EuHDqNWySSkjRgwAANGDBAf/31l/Lz81WuXDlXhwQAAIArcIs5khMmTNDvv/8uSSpTpgxJJAAAuKGYI2mOWySSy5Yt06233qq7775bM2bM0NGjR10dEgAAAK7CLRLJH3/8UT/++KPuvfdeTZkyRRUqVND999+vxYsX69y5c64ODwAAFHPsI2mOWySSklS7dm0lJCRo7969Wr9+vaKjoxUfH6+IiAhXhwYAAIo5dxnaHj9+vCwWi93x91zIMAyNHz9ekZGRCggIUMuWLbVr1y67a2RlZWno0KEqU6aMgoKC1KVLFx06dMghz+lSbpNI/l1QUJACAgLk5+ennJwcV4cDAABww9SuXVtpaWm24+/f8peUlKQpU6ZoxowZSklJUUREhNq2bavTp0/b+sTHx2v58uVasmSJNm7cqDNnzqhTp062r6B2JLdJJFNTU/Xyyy+rVq1aatSokb7//nuNHz9e6enprg4NAAAUc14W5x1F5ePjo4iICNtRtmxZSReqkdOmTdPYsWPVrVs31alTR8nJyTp37pwWL14sSTp58qTmzJmjV199VW3atFGDBg20cOFC7dixQ+vWrXPkI5PkJolkkyZNVK1aNf373/9W3759tX//fn3xxRfq37+/QkJCXB0eAACAaVlZWTp16pTdkZWVddn+v/76qyIjIxUdHa0ePXpo7969ki4U3dLT09WuXTtbX6vVqhYtWmjTpk2SpK1btyonJ8euT2RkpOrUqWPr40hukUi2atVKP/74o7Zv365Ro0apQoUKrg4JAAB4EGfOkUxMTFRISIjdkZiYWGgcjRs31vz58/XZZ59p9uzZSk9PV0xMjI4dO2YbpQ0PD7d7T3h4uO1cenq6/Pz8VLp06cv2cSS32JA8ISHB1SEAAAA4xZgxYzR8+HC7NqvVWmjfDh062H6uW7eumjRpoqpVqyo5OVl33323JMlyyVJwwzAKtF3qWvqY4bJEcvjw4Zo4caKCgoIKPNxLTZky5QZFBXf00ZJ5en/em2r/QA89+viFvyuP3HdXoX17xA1Vp4celSR98elybVr/mfb9vkfnz53VWx98rqASJW9Y3AAKV8LfR/98uIE631lRZUP89WPqcY1O/k7f/36sQN/XBtytfm1q6Jnk7/Tmp7vt2lvWiVT50ACdPZ+rb/cc0QuLt+qXw6du5K2gGHHmNj1Wq/WyiePVBAUFqW7duvr111/1wAMPSLpQdSxfvrytz5EjR2xVyoiICGVnZysjI8OuKnnkyBHFxMSYv4nLcFkiuW3bNtuK7G3btrkqDLi53/f8pPWrlqtidDW79hmLP7V7/cOWzXpn6ku66557bW3ZWedVr1ET1WvURO/PfeOGxAvg6mYMilGtqNIa+MZGpR0/p4ebVdFH/2ynO4f/R2kZ/9s7uFOjKDWqVlaHjxfcT3j73mN6f2OqDv51RqVLWPXcP+prxdi2qvPkh8o3jBt5O4BTZWVlaffu3WrWrJmio6MVERGhtWvXqkGDBpKk7OxsbdiwQZMnT5YkNWzYUL6+vlq7dq26d+8uSUpLS9POnTuVlJTk8PhclkiuX7++0J+Bi85nntPMpOcV99RYrXjvXbtzpULL2L3+fvMG1by9ocqV/9/82vv+X09J0k8/bHV+sACuib+vt7o2rqQe//pCX+/+U5KU+MEP6nRnRfVvV0MTl14oLJQvHahX+jXWAwnr9MEzrQtcZ+7nv9p+PnD0rF5cuk3f/KuLKpUrodQ/TxfoD1yNu+wbPnLkSHXu3FkVK1bUkSNH9NJLL+nUqVPq3bu3LBaL4uPjlZCQoOrVq6t69epKSEhQYGCgevXqJUkKCQlRXFycRowYobCwMIWGhmrkyJGqW7eu2rRp4/B43WKxTb9+/ez2P7ro7Nmz6tevnwsigjuY90aS6t/VVHXuKHwY+6KTGce0/buv1bJ9lxsUGQCzfLwt8vH20vkc+/3szmfnqkmNcpIuDDHOfvIevbZyl34+dOKq1wy0+uiRltWU+udpHfrrrDPChgfwslicdhTFoUOH1LNnT9WoUUPdunWTn5+fvvnmG1WqVEmSNHr0aMXHx2vw4MFq1KiR/vjjD61Zs0YlS/5v6tbUqVP1wAMPqHv37mratKkCAwO1cuVKeXt7O/SZSW6y2CY5OVmTJk2yewiSlJmZqfnz5+vdd9+9zDsvlHwvXUKfnZUlP5NzEeAeNn+5Rvt+26MXX5931b5frftE/gFBatS0lfMDA3BdzvzffMZnut2uPX+c1JET5/VQ02g1qlZWv6dfmN84vGsd5eYZmrlq9xWv1b9dDU2MbagS/r7a88cJdX15rXLy8m/EbQBOs2TJkiuet1gsGj9+vMaPH3/ZPv7+/po+fbqmT5/u4OgKcmlF8tSpUzp58qQMw9Dp06ft9lfKyMjQp59+qnLlyl3xGoUtqZ83k8U5N7NjR//UgllT9MToCfLzu/p/EGz4bKVi7m1/TX0BuN6ANzbKYpF+ndVdxxY9osc71NT7X+9VXr6h+tGheqJDLT0+c+NVr/P+V3t1zzMrdd/41fo97bSS41vI6usWA224CVmceBRnLq1IlipVyvY9krfeemuB8xaLRRMmTLjiNQpbUr/j8HmHxokbK/XX3Tp14rief7K3rS0/P097dm7T2o/+rXkrN8rr/8rzP+/cprRD+/Xkcy+7KlwARZT652l1mPCZAq0+Khngqz9PZGreU821/8gZxdQMV9lgf+1+4x+2/j7eXkp4tJEGd6ilOkOX2dpPZeboVGaOfk8/re9+OaqD7/ZQ5zsr6YNNqa64LcAjuTSRXL9+vQzD0L333qtly5YpNDTUds7Pz0+VKlVSZGTkFa9R2JJ6v2Os2LuZ1a5/pxJnvWfX9varLyoyqrI6dX/MlkRK0obVHym6+m2qVKXgf4gAcG/nsnJ1LitXpYL81Pr2Cnph0Rb959sDWr8jza7fiufaasl/f9fCL3+74vUsFgsVSZhX3EuHTuLSRLJFixaSLnzlT8WKFZ2yUSZuPgGBQYqqXNWuzeofoBLBIXbt586e0Xdffa5eA58q9Donjv+lkxnH9efhg5Kkg/t+U0BAkMLKhatESb56E3CV1rdHyiLp18OnVCWipF56pJF+PXxSC778Tbl5ho6fsZ/3npObrz9PZurXtAtzKCuXK6EHYyrr8x8O669TWYoMDdTTXevofHauPtv2hwvuCPBcLkskf/zxR9WpU0deXl46efKkduzYcdm+9erVu4GR4WbxzYa1MmSoScv2hZ7//JMPtXzRO7bXL40cJEkaOPwFNW/X6YbECKCg4ABfje/ZUBXCApVxJkv/+faAXlzyvXLzrm006XxOnprcFq7BHWqpVAk/HTlxXl///KfaPL9Kf51iahPMsVCSNMViGK7ZudXLy0vp6ekqV66cvLy8ZLFYVFgoFotFeXl5hVzh8lJSTzoqTABu5t5nV7g6BABOcnpp76t3cpJvf3de7tC4avEdBXNZRTI1NVVly5a1/QwAAOAqzK4zx2WJ5MWNNS/9GQAA4EYjjzTHLZa3JScn65NPPrG9Hj16tEqVKqWYmBjt37/fhZEBAADgctwikUxISFBAQIAkafPmzZoxY4aSkpJUpkwZPf300y6ODgAAFHvsSG6KW3xF4sGDB1WtWjVJ0ooVK/SPf/xDAwcOVNOmTdWyZUvXBgcAAIBCuUVFskSJEjp27Jgkac2aNWrTpo2kC98VmZmZ6crQAACAB7A48U9x5hYVybZt26p///5q0KCBfvnlF3Xs2FGStGvXLlWuXNm1wQEAAKBQblGRfOONN9SkSRMdPXpUy5YtU1hYmCRp69at6tmzp4ujAwAAxZ3F4ryjOHOLimSpUqU0Y8aMAu0TJkxwQTQAAAC4Fm6RSErSiRMnNGfOHO3evVsWi0U1a9ZUXFycQkKK727wAADAPRTzwqHTuMXQ9pYtW1S1alVNnTpVx48f119//aWpU6eqatWq+v77710dHgAAKO7Y/scUt6hIPv300+rSpYtmz54tH58LIeXm5qp///6Kj4/Xf//7XxdHCAAAgEu5RSK5ZcsWuyRSknx8fDR69Gg1atTIhZEBAABPUNy36XEWtxjaDg4O1oEDBwq0Hzx4UCVLlnRBRAAAALgat0gkH374YcXFxWnp0qU6ePCgDh06pCVLlqh///5s/wMAAJyO7X/McYuh7VdeeUVeXl567LHHlJubK0ny9fXVE088oUmTJrk4OgAAABTGpYnkuXPnNGrUKK1YsUI5OTl64IEH9OSTTyokJETVqlVTYGCgK8MDAAAeopgXDp3GpYnkuHHjNG/ePMXGxiogIECLFy9Wfn6+/v3vf7syLAAAAFwDlyaSH374oebMmaMePXpIkmJjY9W0aVPl5eXJ29vblaEBAABPQknSFJcutjl48KCaNWtme33XXXfJx8dHhw8fdmFUAADA01ic+Kc4c2kimZeXJz8/P7s2Hx8f24IbAAAAuC+XDm0bhqE+ffrIarXa2s6fP6/HH39cQUFBtrYPP/zQFeEBAAAPUdy36XEWlyaSvXv3LtD2yCOPuCASAAAAFJVLE8m5c+e68uMBAAAksdbGLLf4ZhsAAADcfNzim20AAABcipKkKVQkAQAAYAoVSQAA4PGK+36PzkJFEgAAAKZQkQQAAB6PfSTNIZEEAAAejzzSHIa2AQAAYAoVSQAAAEqSplCRBAAAgClUJAEAgMdj+x9zqEgCAADAFCqSAADA47H9jzlUJAEAAGAKFUkAAODxKEiaQyIJAABAJmkKQ9sAAAAwhYokAADweGz/Yw4VSQAAAJhCRRIAAHg8tv8xh4okAACAm0pMTJTFYlF8fLytzTAMjR8/XpGRkQoICFDLli21a9cuu/dlZWVp6NChKlOmjIKCgtSlSxcdOnTI4fGRSAIAAI9nceJhVkpKit5++23Vq1fPrj0pKUlTpkzRjBkzlJKSooiICLVt21anT5+29YmPj9fy5cu1ZMkSbdy4UWfOnFGnTp2Ul5d3HREVRCIJAADgZs6cOaPY2FjNnj1bpUuXtrUbhqFp06Zp7Nix6tatm+rUqaPk5GSdO3dOixcvliSdPHlSc+bM0auvvqo2bdqoQYMGWrhwoXbs2KF169Y5NE4SSQAAACeWJLOysnTq1Cm7Iysr64rhDBkyRB07dlSbNm3s2lNTU5Wenq527drZ2qxWq1q0aKFNmzZJkrZu3aqcnBy7PpGRkapTp46tj6OQSAIAAI9nceKfxMREhYSE2B2JiYmXjWXJkiX6/vvvC+2Tnp4uSQoPD7drDw8Pt51LT0+Xn5+fXSXz0j6OwqptAAAAJxozZoyGDx9u12a1Wgvte/DgQT311FNas2aN/P39L3tNyyXLzA3DKNB2qWvpU1RUJAEAgMezWJx3WK1WBQcH2x2XSyS3bt2qI0eOqGHDhvLx8ZGPj482bNig119/XT4+PrZK5KWVxSNHjtjORUREKDs7WxkZGZft4ygkkgAAAG6idevW2rFjh7Zv3247GjVqpNjYWG3fvl1VqlRRRESE1q5da3tPdna2NmzYoJiYGElSw4YN5evra9cnLS1NO3futPVxFIa2AQCAx3OX/chLliypOnXq2LUFBQUpLCzM1h4fH6+EhARVr15d1atXV0JCggIDA9WrVy9JUkhIiOLi4jRixAiFhYUpNDRUI0eOVN26dQss3rleJJIAAAA3kdGjRyszM1ODBw9WRkaGGjdurDVr1qhkyZK2PlOnTpWPj4+6d++uzMxMtW7dWvPmzZO3t7dDY7EYhmE49IpuICX1pKtDAOAk9z67wtUhAHCS00t7u+yz9x0777RrVw67/KKZmx1zJAEAAGAKQ9sAAMDjWdxmluTNhUQSAAB4PAdvr+gxGNoGAACAKVQkAQCAx6MgaQ4VSQAAAJhCRRIAAHg85kiaQ0USAAAAplCRBAAAYJakKVQkAQAAYAoVSQAA4PGYI2kOiSQAAPB45JHmMLQNAAAAU6hIAgAAj8fQtjlUJAEAAGAKFUkAAODxLMySNIWKJAAAAEyhIgkAAEBB0hQqkgAAADCFiiQAAPB4FCTNIZEEAAAej+1/zGFoGwAAAKZQkQQAAB6P7X/MoSIJAAAAU6hIAgAAUJA0hYokAAAATKEiCQAAPB4FSXOoSAIAAMAUKpIAAMDjsY+kOSSSAADA47H9jzkMbQMAAMAUKpIAAMDjMbRtDhVJAAAAmEIiCQAAAFNIJAEAAGAKcyQBAIDHY46kOVQkAQAAYAoVSQAA4PHYR9IcEkkAAODxGNo2h6FtAAAAmEJFEgAAeDwKkuZQkQQAAIApVCQBAAAoSZpCRRIAAACmUJEEAAAej+1/zKEiCQAAAFOoSAIAAI/HPpLmUJEEAACAKVQkAQCAx6MgaQ6JJAAAAJmkKQxtAwAAuImZM2eqXr16Cg4OVnBwsJo0aaJVq1bZzhuGofHjxysyMlIBAQFq2bKldu3aZXeNrKwsDR06VGXKlFFQUJC6dOmiQ4cOOSVeEkkAAODxLE78UxS33HKLJk2apC1btmjLli2699571bVrV1uymJSUpClTpmjGjBlKSUlRRESE2rZtq9OnT9uuER8fr+XLl2vJkiXauHGjzpw5o06dOikvL8+hz0ySLIZhGA6/qoulpJ50dQgAnOTeZ1e4OgQATnJ6aW+XfXZmjvOuHeB7fe8PDQ3Vv/71L/Xr10+RkZGKj4/XM888I+lC9TE8PFyTJ0/WoEGDdPLkSZUtW1YLFizQww8/LEk6fPiwoqKi9Omnn6p9+/bXezt2qEgCAACPZ7E478jKytKpU6fsjqysrKvGlJeXpyVLlujs2bNq0qSJUlNTlZ6ernbt2tn6WK1WtWjRQps2bZIkbd26VTk5OXZ9IiMjVadOHVsfRyKRBAAAcKLExESFhITYHYmJiZftv2PHDpUoUUJWq1WPP/64li9frlq1aik9PV2SFB4ebtc/PDzcdi49PV1+fn4qXbr0Zfs4UrFctX1ndIirQ8ANkpWVpcTERI0ZM0ZWq9XV4eAGcOXQF24sfr9xI/k7MSMaM2aMhg8fbtd2pb/TNWrU0Pbt23XixAktW7ZMvXv31oYNG2znLZfsnm4YRoG2S11LHzOoSOKmlpWVpQkTJlzTEAGAmwu/3ygurFarbRX2xeNKiaSfn5+qVaumRo0aKTExUbfffrtee+01RURESFKByuKRI0dsVcqIiAhlZ2crIyPjsn0ciUQSAADAjRmGoaysLEVHRysiIkJr1661ncvOztaGDRsUExMjSWrYsKF8fX3t+qSlpWnnzp22Po5ULIe2AQAAbkbPPfecOnTooKioKJ0+fVpLlizRl19+qdWrV8tisSg+Pl4JCQmqXr26qlevroSEBAUGBqpXr16SpJCQEMXFxWnEiBEKCwtTaGioRo4cqbp166pNmzYOj5dEEgAAwE38+eefevTRR5WWlqaQkBDVq1dPq1evVtu2bSVJo0ePVmZmpgYPHqyMjAw1btxYa9asUcmSJW3XmDp1qnx8fNS9e3dlZmaqdevWmjdvnry9vR0eb7HcRxKeg8n4QPHF7zfg/kgkAQAAYAqLbQAAAGAKiSQAAABMIZEEAACAKSSS8CiVK1fWtGnTXB0GgCvYt2+fLBaLtm/ffsV+LVu2VHx8/A2JCUDhSCThMH369JHFYtGkSZPs2lesWOGUr2W6knnz5qlUqVIF2lNSUjRw4MAbGgtQXF38nbdYLPL19VWVKlU0cuRInT179rquGxUVpbS0NNWpU0eS9OWXX8pisejEiRN2/T788ENNnDjxuj4LwPUhkYRD+fv7a/LkyQW+msldlC1bVoGBga4OAyg27rvvPqWlpWnv3r166aWX9Oabb2rkyJHXdU1vb29FRETIx+fKWx2Hhoba7Z0H4MYjkYRDtWnTRhEREUpMTLxsn02bNql58+YKCAhQVFSUhg0bZlfBSEtLU8eOHRUQEKDo6GgtXry4wJD0lClTVLduXQUFBSkqKkqDBw/WmTNnJF2oXvTt21cnT560VUvGjx8vyX5ou2fPnurRo4ddbDk5OSpTpozmzp0r6cLXUiUlJalKlSoKCAjQ7bffrg8++MABTwooHqxWqyIiIhQVFaVevXopNjZWK1asUFZWloYNG6Zy5crJ399f99xzj1JSUmzvy8jIUGxsrMqWLauAgABVr17d9nv396Htffv2qVWrVpKk0qVLy2KxqE+fPpLsh7bHjBmju+++u0B89erV07hx42yv586dq5o1a8rf31+33Xab3nzzTSc9GcAzkEjCoby9vZWQkKDp06fr0KFDBc7v2LFD7du3V7du3fTjjz9q6dKl2rhxo5588klbn8cee0yHDx/Wl19+qWXLluntt9/WkSNH7K7j5eWl119/XTt37lRycrK++OILjR49WpIUExOjadOmKTg4WGlpaUpLSyu0QhIbG6uPPvrIloBK0meffaazZ8/qwQcflCT985//1Ny5czVz5kzt2rVLTz/9tB555BFt2LDBIc8LKG4CAgKUk5Oj0aNHa9myZUpOTtb333+vatWqqX379jp+/Lgk6fnnn9dPP/2kVatWaffu3Zo5c6bKlClT4HpRUVFatmyZJGnPnj1KS0vTa6+9VqBfbGysvv32W/3++++2tl27dmnHjh2KjY2VJM2ePVtjx47Vyy+/rN27dyshIUHPP/+8kpOTnfEoAM9gAA7Su3dvo2vXroZhGMbdd99t9OvXzzAMw1i+fLlx8a/ao48+agwcONDufV999ZXh5eVlZGZmGrt37zYkGSkpKbbzv/76qyHJmDp16mU/+/333zfCwsJsr+fOnWuEhIQU6FepUiXbdbKzs40yZcoY8+fPt53v2bOn8dBDDxmGYRhnzpwx/P39jU2bNtldIy4uzujZs+eVHwbgAf7+O28YhvHtt98aYWFhxj/+8Q/D19fXWLRoke1cdna2ERkZaSQlJRmGYRidO3c2+vbtW+h1U1NTDUnGtm3bDMMwjPXr1xuSjIyMDLt+LVq0MJ566inb63r16hkvvvii7fWYMWOMO++80/Y6KirKWLx4sd01Jk6caDRp0qQotw3gb6hIwikmT56s5ORk/fTTT3btW7du1bx581SiRAnb0b59e+Xn5ys1NVV79uyRj4+P7rjjDtt7qlWrptKlS9tdZ/369Wrbtq0qVKigkiVL6rHHHtOxY8eKNMnf19dXDz30kBYtWiRJOnv2rP7zn//Yqhc//fSTzp8/r7Zt29rFO3/+fLuqB+DJPv74Y5UoUUL+/v5q0qSJmjdvrqFDhyonJ0dNmza19fP19dVdd92l3bt3S5KeeOIJLVmyRPXr19fo0aO1adOm644lNjbW9vtsGIbee+892+/z0aNHdfDgQcXFxdn9Pr/00kv8PgPX4cozmQGTmjdvrvbt2+u5556zzWeSpPz8fA0aNEjDhg0r8J6KFStqz549hV7P+Ns3ee7fv1/333+/Hn/8cU2cOFGhoaHauHGj4uLilJOTU6Q4Y2Nj1aJFCx05ckRr166Vv7+/OnToYItVkj755BNVqFDB7n187y9wQatWrTRz5kz5+voqMjJSvr6++uGHHySpwG4NhmHY2jp06KD9+/frk08+0bp169S6dWsNGTJEr7zyiulYevXqpWeffVbff/+9MjMzdfDgQds86Iu/z7Nnz1bjxo3t3uft7W36MwFPRyIJp5k0aZLq16+vW2+91dZ2xx13aNeuXapWrVqh77ntttuUm5urbdu2qWHDhpKk3377zW7bjy1btig3N1evvvqqvLwuFNXff/99u+v4+fkpLy/vqjHGxMQoKipKS5cu1apVq/TQQw/Jz89PklSrVi1ZrVYdOHBALVq0KNK9A54iKCiowO9ztWrV5Ofnp40bN6pXr16SLixk27Jli92+j2XLllWfPn3Up08fNWvWTKNGjSo0kbz4O3m13+lbbrlFzZs316JFi5SZmak2bdooPDxckhQeHq4KFSpo7969tiolgOtHIgmnqVu3rmJjYzV9+nRb2zPPPKO7775bQ4YM0YABAxQUFKTdu3dr7dq1mj59um677Ta1adNGAwcOtFU5RowYoYCAAFslo2rVqsrNzdX06dPVuXNnff3115o1a5bdZ1euXFlnzpzR559/rttvv12BgYGFbvtjsVjUq1cvzZo1S7/88ovWr19vO1eyZEmNHDlSTz/9tPLz83XPPffo1KlT2rRpk0qUKKHevXs76ckBN7egoCA98cQTGjVqlEJDQ1WxYkUlJSXp3LlziouLkyS98MILatiwoWrXrq2srCx9/PHHqlmzZqHXq1SpkiwWiz7++GPdf//9CggIUIkSJQrtGxsbq/Hjxys7O1tTp061Ozd+/HgNGzZMwcHB6tChg7KysrRlyxZlZGRo+PDhjn0IgKdw8RxNFCOXTrw3DMPYt2+fYbVajb//Vfvuu++Mtm3bGiVKlDCCgoKMevXqGS+//LLt/OHDh40OHToYVqvVqFSpkrF48WKjXLlyxqxZs2x9pkyZYpQvX94ICAgw2rdvb8yfP7/AZPzHH3/cCAsLMyQZ48aNMwzDfrHNRbt27TIkGZUqVTLy8/PtzuXn5xuvvfaaUaNGDcPX19coW7as0b59e2PDhg3X97CAYqCw3/mLMjMzjaFDhxplypQxrFar0bRpU+O7776znZ84caJRs2ZNIyAgwAgNDTW6du1q7N271zCMgottDMMwXnzxRSMiIsKwWCxG7969DcMouNjGMAwjIyPDsFqtRmBgoHH69OkCcS1atMioX7++4efnZ5QuXdpo3ry58eGHH17XcwA8mcUw/jb5DHBDhw4dUlRUlG0eFQAAcA8kknA7X3zxhc6cOaO6desqLS1No0eP1h9//KFffvlFvr6+rg4PAAD8H+ZIwu3k5OToueee0969e1WyZEnFxMRo0aJFJJEAALgZKpIAAAAwhQ3JAQAAYAqJJAAAAEwhkQQAAIApJJIAAAAwhUQSAAAAppBIAjBt/Pjxql+/vu11nz599MADD9zwOPbt2yeLxaLt27c77TMuvVczbkScAHAjkUgCxUyfPn1ksVhksVjk6+urKlWqaOTIkTp79qzTP/u1117TvHnzrqnvjU6qWrZsqfj4+BvyWQDgKdiQHCiG7rvvPs2dO1c5OTn66quv1L9/f509e1YzZ84s0DcnJ8dhm72HhIQ45DoAgJsDFUmgGLJarYqIiFBUVJR69eql2NhYrVixQtL/hmjfffddValSRVarVYZh6OTJkxo4cKDKlSun4OBg3Xvvvfrhhx/srjtp0iSFh4erZMmSiouL0/nz5+3OXzq0nZ+fr8mTJ6tatWqyWq2qWLGiXn75ZUlSdHS0JKlBgwayWCxq2bKl7X1z585VzZo15e/vr9tuu01vvvmm3ed89913atCggfz9/dWoUSNt27btup/ZM888o1tvvVWBgYGqUqWKnn/+eeXk5BTo99ZbbykqKkqBgYF66KGHdOLECbvzV4v97zIyMhQbG6uyZcsqICBA1atX19y5c6/7XgDgRqEiCXiAgIAAu6Tot99+0/vvv69ly5bJ29tbktSxY0eFhobq008/VUhIiN566y21bt1av/zyi0JDQ/X+++9r3LhxeuONN9SsWTMtWLBAr7/+uqpUqXLZzx0zZoxmz56tqVOn6p577lFaWpp+/vlnSReSwbvuukvr1q1T7dq15efnJ0maPXu2xo0bpxkzZqhBgwbatm2bBgwYoKCgIPXu3Vtnz55Vp06ddO+992rhwoVKTU3VU089dd3PqGTJkpo3b54iIyO1Y8cODRgwQCVLltTo0aMLPLeVK1fq1KlTiouL05AhQ7Ro0aJriv1Szz//vH766SetWrVKZcqU0W+//abMzMzrvhcAuGEMAMVK7969ja5du9pef/vtt0ZYWJjRvXt3wzAMY9y4cYavr69x5MgRW5/PP//cCA4ONs6fP293rapVqxpvvfWWYRiG0aRJE+Pxxx+3O9+4cWPj9ttvL/SzT506ZVitVmP27NmFxpmammpIMrZt22bXHhUVZSxevNiubeLEiUaTJk0MwzCMt956ywgNDTXOnj1rOz9z5sxCr/V3LVq0MJ566qnLnr9UUlKS0bBhQ9vrcePGGd7e3sbBgwdtbatWrTK8vLyMtLS0a4r90nvu3Lmz0bdv32uOCQDcDRVJoBj6+OOPVaJECeXm5ionJ0ddu3bV9OnTbecrVaqksmXL2l5v3bpVZ86cUVhYmN11MjMz9fvvv0uSdu/erccff9zufJMmTbR+/fpCY9i9e7eysrLUunXra4776NGjOnjwoOLi4jRgwABbe25urm3+5e7du3X77bcrMDDQLo7r9cEHH2jatGn67bffdObMGeXm5io4ONiuT8WKFXXLLbfYfW5+fr727Nkjb2/vq8Z+qSeeeEIPPvigvv/+e7Vr104PPPCAYmJirvteAOBGIZEEiqFWrVpp5syZ8vX1VWRkZIHFNEFBQXav8/PzVb58eX355ZcFrlWqVClTMQQEBBT5Pfn5+ZIuDBE3btzY7tzFIXjDMEzFcyXffPONevTooQkTJqh9+/YKCQnRkiVL9Oqrr17xfRaLxfa/1xL7pTp06KD9+/frk08+0bp169S6dWsNGTJEr7zyigPuCgCcj0QSKIaCgoJUrVq1a+5/xx13KD09XT4+PqpcuXKhfWrWrKlvvvlGjz32mK3tm2++uew1q1evroCAAH3++efq379/gfMX50Tm5eXZ2sLDw1WhQgXt3btXsbGxhV63Vq1aWrBggTIzM23J6pXiuBZff/21KlWqpLFjx9ra9u/fX6DfgQMHdPjwYUVGRkqSNm/eLC8vL916663XFHthypYtqz59+qhPnz5q1qyZRo0aRSIJ4KZBIglAbdq0UZMmTfTAAw9o8uTJqlGjhg4fPqxPP/1UDzzwgBo1aqSnnnpKvXv3VqNGjXTPPfdo0aJF2rVr12UX2/j7++uZZ57R6NGj5efnp6ZNm+ro0aPatWuX4uLiVK5cOQUEBGj16tW65ZZb5O/vr5CQEI0fP17Dhg1TcHCwOnTooKysLG3ZskUZGRkaPny4evXqpbFjxyouLk7//Oc/tW/fvmtOvI4ePVpg38qIiAhVq1ZNBw4c0JIlS3TnnXfqk08+0fLlywu9p969e+uVV17RqVOnNGzYMHXv3l0RERGSdNXYL/XCCy+oYcOGql27trKysvTxxx+rZs2a13QvAOAWXD1JE4BjXbrY5lLjxo2zWyBz0alTp4yhQ4cakZGRhq+vrxEVFWXExsYaBw4csPV5+eWXjTJlyhglSpQwevfubYwePfqyi20MwzDy8vKMl156yahUqZLh6+trVKxY0UhISLCdnz17thEVFWV4eXkZLVq0sLUvWrTIqF+/vuHn52eULl3aaN68ufHhhx/azm/evNm4/fbbDT8/P6N+/frGsmXLrmmxjaQCx7hx4wzDMIxRo0YZYWFhRokSJYyHH37YmDp1qhESElLgub355ptGZGSk4e/vb3Tr1s04fvy43edcKfZLF9tMnDjRqFmzphEQEGCEhoYaXbt2Nfbu3XvZewAAd2MxDCdMOAIAAECxx4bkAAAAMIVEEgAAAKaQSAIAAMAUEkkAAACYQiIJAAAAU0gkAQAAYAqJJAAAAEwhkQQAAIApJJIAAAAwhUQSAAAAppBIAgAAwJT/D9a0PlZc51xiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70      1353\n",
      "           1       0.72      0.68      0.70      1414\n",
      "\n",
      "    accuracy                           0.70      2767\n",
      "   macro avg       0.70      0.70      0.70      2767\n",
      "weighted avg       0.70      0.70      0.70      2767\n",
      "\n",
      "Confusion Matrix:\n",
      " [[975 378]\n",
      " [451 963]]\n",
      "Accuracy Score: 0.7003975424647633\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l1; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.0s\n",
      "[CV] END ................................C=0.001, penalty=l2; total time=   0.0s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.0s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.0s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.0s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.0s\n",
      "[CV] END .................................C=0.01, penalty=l2; total time=   0.0s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END .................................C=0.01, penalty=l1; total time=   0.1s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.3s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.3s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.3s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.4s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.4s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.4s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.4s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.5s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.4s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.4s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.4s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.5s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.4s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.4s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.5s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.4s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.4s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.4s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.4s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.4s\n",
      "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Best Score: 0.7081408985501212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model with 'liblinear' solver\n",
    "logistic_regression = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Create a dictionary of all values you want to test for C and penalty\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # The norm used in the penalization\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best parameters\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model with your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6985905312612938\n",
      "Confusion Matrix:\n",
      " [[972 381]\n",
      " [453 961]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70      1353\n",
      "           1       0.72      0.68      0.70      1414\n",
      "\n",
      "    accuracy                           0.70      2767\n",
      "   macro avg       0.70      0.70      0.70      2767\n",
      "weighted avg       0.70      0.70      0.70      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the best estimator to make predictions on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the evaluation results\n",
    "print('Accuracy:', accuracy)\n",
    "print('Confusion Matrix:\\n', conf_mat)\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8015901698590532\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1353\n",
      "           1       0.81      0.81      0.81      1414\n",
      "\n",
      "    accuracy                           0.80      2767\n",
      "   macro avg       0.80      0.80      0.80      2767\n",
      "weighted avg       0.80      0.80      0.80      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use gridSearch to find and use  the optimal hyperparameters, to increase the performance of the Random Forest model even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrandom_forest, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit GridSearchCV to the training data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Get the best parameters and best score\u001b[39;00m\n\u001b[1;32m     19\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthreads\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39mcurr_sample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_fit(\n\u001b[1;32m    960\u001b[0m         X,\n\u001b[1;32m    961\u001b[0m         y,\n\u001b[1;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39mcheck_input,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.8044813877846043\n"
     ]
    }
   ],
   "source": [
    "# Calculate training accuracy\n",
    "train_accuracy = best_model.score(X_train, y_train)\n",
    "\n",
    "# Calculate testing accuracy\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM feature based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because 1_grams is text based it needs to be vectorized to enable the model to understand it.\n",
    "Therefore we split the dataset in both numerical and text-based features, and the we vectorize the 1_grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "model = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# Train the SVM model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6975063245392121\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.71      1353\n",
      "           1       0.73      0.66      0.69      1414\n",
      "\n",
      "    accuracy                           0.70      2767\n",
      "   macro avg       0.70      0.70      0.70      2767\n",
      "weighted avg       0.70      0.70      0.70      2767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8995cc79525bd2f03bf06fe7351d86fcc477a350b98b661267de2f13aa6250"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
