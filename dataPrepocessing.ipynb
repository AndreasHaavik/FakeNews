{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Understanding and Preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('Fake.csv')\n",
    "true = pd.read_csv('True.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21417"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake)\n",
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "21412  'Fully committed' NATO backs new U.S. approach...   \n",
       "21413  LexisNexis withdrew two products from Chinese ...   \n",
       "21414  Minsk cultural hub becomes haven from authorities   \n",
       "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
       "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text    subject  \\\n",
       "0      Donald Trump just couldn t wish all Americans ...       News   \n",
       "1      House Intelligence Committee Chairman Devin Nu...       News   \n",
       "2      On Friday, it was revealed that former Milwauk...       News   \n",
       "3      On Christmas day, Donald Trump announced that ...       News   \n",
       "4      Pope Francis used his annual Christmas Day mes...       News   \n",
       "...                                                  ...        ...   \n",
       "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...  worldnews   \n",
       "21413  LONDON (Reuters) - LexisNexis, a provider of l...  worldnews   \n",
       "21414  MINSK (Reuters) - In the shadow of disused Sov...  worldnews   \n",
       "21415  MOSCOW (Reuters) - Vatican Secretary of State ...  worldnews   \n",
       "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...  worldnews   \n",
       "\n",
       "                    date  label  \n",
       "0      December 31, 2017      1  \n",
       "1      December 31, 2017      1  \n",
       "2      December 30, 2017      1  \n",
       "3      December 29, 2017      1  \n",
       "4      December 25, 2017      1  \n",
       "...                  ...    ...  \n",
       "21412   August 22, 2017       0  \n",
       "21413   August 22, 2017       0  \n",
       "21414   August 22, 2017       0  \n",
       "21415   August 22, 2017       0  \n",
       "21416   August 22, 2017       0  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['label'] = 1\n",
    "true['label']=0\n",
    "\n",
    "df_concated = pd.concat([fake, true])\n",
    "permutation = np.random.permutation(len(df_concated))\n",
    "df = df_concated.iloc[permutation]\n",
    "df_concated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44689, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = df.isnull().sum()\n",
    "\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Dan Rather: Mueller’s Russia Investigation Ha...</td>\n",
       "      <td>Legendary journalist Dan Rather says that Robe...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17421</th>\n",
       "      <td>Death toll from blasts in Somalia's capital Mo...</td>\n",
       "      <td>MOGADISHU (Reuters) - More than 200 people wer...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>U.S. House Republicans to discuss whether to i...</td>\n",
       "      <td>WASHINGTON (Reuters) - Members of the Republic...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14076</th>\n",
       "      <td>THIS IS BIG! Tennessee Votes To Sue The Feds O...</td>\n",
       "      <td>This is big! In the name of security and state...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11886</th>\n",
       "      <td>HIGH ROAD! MARTIN LUTHER KING III MEETS WITH T...</td>\n",
       "      <td>Martin Luther King III met with president-elec...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20185</th>\n",
       "      <td>VIDEO SHOWS SCARY TRUTH About What Decades Of ...</td>\n",
       "      <td>We live near the city of Detroit, and anyone c...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>Rosneft's Sechin to miss hearing at ex-ministe...</td>\n",
       "      <td>MOSCOW (Reuters) - The head of Russian state o...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Trump Supporter In Phoenix Just Threatened Jo...</td>\n",
       "      <td>Donald Trump, in his ongoing effort to spur on...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>For Donald Trump, going on about golf is par f...</td>\n",
       "      <td>TURNBERRY, Scotland (Reuters) - Donald Trump f...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15101</th>\n",
       "      <td>German parties see momentum in coalition talks...</td>\n",
       "      <td>BERLIN (Reuters) - German parties cited progre...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "464     Dan Rather: Mueller’s Russia Investigation Ha...   \n",
       "17421  Death toll from blasts in Somalia's capital Mo...   \n",
       "8239   U.S. House Republicans to discuss whether to i...   \n",
       "14076  THIS IS BIG! Tennessee Votes To Sue The Feds O...   \n",
       "11886  HIGH ROAD! MARTIN LUTHER KING III MEETS WITH T...   \n",
       "...                                                  ...   \n",
       "20185  VIDEO SHOWS SCARY TRUTH About What Decades Of ...   \n",
       "14292  Rosneft's Sechin to miss hearing at ex-ministe...   \n",
       "509     Trump Supporter In Phoenix Just Threatened Jo...   \n",
       "8988   For Donald Trump, going on about golf is par f...   \n",
       "15101  German parties see momentum in coalition talks...   \n",
       "\n",
       "                                                    text       subject  label  \n",
       "464    Legendary journalist Dan Rather says that Robe...          News      1  \n",
       "17421  MOGADISHU (Reuters) - More than 200 people wer...     worldnews      0  \n",
       "8239   WASHINGTON (Reuters) - Members of the Republic...  politicsNews      0  \n",
       "14076  This is big! In the name of security and state...      politics      1  \n",
       "11886  Martin Luther King III met with president-elec...      politics      1  \n",
       "...                                                  ...           ...    ...  \n",
       "20185  We live near the city of Detroit, and anyone c...     left-news      1  \n",
       "14292  MOSCOW (Reuters) - The head of Russian state o...     worldnews      0  \n",
       "509    Donald Trump, in his ongoing effort to spur on...          News      1  \n",
       "8988   TURNBERRY, Scotland (Reuters) - Donald Trump f...  politicsNews      0  \n",
       "15101  BERLIN (Reuters) - German parties cited progre...     worldnews      0  \n",
       "\n",
       "[44689 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_date = df.drop(columns=['date'])\n",
    "\n",
    "df_no_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make text Preprocessing, where are going through these steps: \n",
    "* Lowercasing\n",
    "* Removing Special Characters and Punctuation\n",
    "* Tokenization\n",
    "* Removing Stopwords\n",
    "* Lemmatization (We'll prefer this over stemming as it's generally more effective for understanding the context of words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/claramillekalo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/claramillekalo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/claramillekalo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')  # for tokenization\n",
    "nltk.download('stopwords')  # for stopwords\n",
    "nltk.download('wordnet')  # for lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_subject(subject):\n",
    "    # Convert text to lowercase\n",
    "    subject = subject.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    subject = ''.join(char for char in subject if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(subject)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_title(title):\n",
    "    # Convert text to lowercase\n",
    "    title = title.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    title = ''.join(char for char in title if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(title)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it contains a column named 'text'\n",
    "df_no_date['cleaned_text'] = df_no_date['text'].apply(preprocess_text)\n",
    "df_no_date['cleaned_subject'] = df_no_date['subject'].apply(preprocess_subject)\n",
    "df_no_date['cleaned_title'] = df_no_date['title'].apply(preprocess_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_date.drop(columns=['title', 'subject', 'text'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_subject</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1</td>\n",
       "      <td>legendary journalist dan rather say robert mue...</td>\n",
       "      <td>news</td>\n",
       "      <td>dan rather muellers russia investigation trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17421</th>\n",
       "      <td>0</td>\n",
       "      <td>mogadishu reuters 200 people killed twin bomb ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>death toll blast somalia capital mogadishu top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>0</td>\n",
       "      <td>washington reuters member republican majority ...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>u house republican discus whether impeach irs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14076</th>\n",
       "      <td>1</td>\n",
       "      <td>big name security state sovereignty tennessee ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>big tennessee vote sue fed refugee resettlement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11886</th>\n",
       "      <td>1</td>\n",
       "      <td>martin luther king iii met presidentelect dona...</td>\n",
       "      <td>politics</td>\n",
       "      <td>high road martin luther king iii meet trump ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20185</th>\n",
       "      <td>1</td>\n",
       "      <td>live near city detroit anyone could literally ...</td>\n",
       "      <td>leftnews</td>\n",
       "      <td>video show scary truth decade democrat ruled d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>0</td>\n",
       "      <td>moscow reuters head russian state oil giant ro...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>rosnefts sechin miss hearing exminister corrup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1</td>\n",
       "      <td>donald trump ongoing effort spur civil war hol...</td>\n",
       "      <td>news</td>\n",
       "      <td>trump supporter phoenix threatened john mccain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>0</td>\n",
       "      <td>turnberry scotland reuters donald trump flew n...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>donald trump going golf par course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15101</th>\n",
       "      <td>0</td>\n",
       "      <td>berlin reuters german party cited progress fri...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>german party see momentum coalition talk despi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text  \\\n",
       "464        1  legendary journalist dan rather say robert mue...   \n",
       "17421      0  mogadishu reuters 200 people killed twin bomb ...   \n",
       "8239       0  washington reuters member republican majority ...   \n",
       "14076      1  big name security state sovereignty tennessee ...   \n",
       "11886      1  martin luther king iii met presidentelect dona...   \n",
       "...      ...                                                ...   \n",
       "20185      1  live near city detroit anyone could literally ...   \n",
       "14292      0  moscow reuters head russian state oil giant ro...   \n",
       "509        1  donald trump ongoing effort spur civil war hol...   \n",
       "8988       0  turnberry scotland reuters donald trump flew n...   \n",
       "15101      0  berlin reuters german party cited progress fri...   \n",
       "\n",
       "      cleaned_subject                                      cleaned_title  \n",
       "464              news  dan rather muellers russia investigation trump...  \n",
       "17421       worldnews  death toll blast somalia capital mogadishu top...  \n",
       "8239     politicsnews  u house republican discus whether impeach irs ...  \n",
       "14076        politics    big tennessee vote sue fed refugee resettlement  \n",
       "11886        politics  high road martin luther king iii meet trump ti...  \n",
       "...               ...                                                ...  \n",
       "20185        leftnews  video show scary truth decade democrat ruled d...  \n",
       "14292       worldnews  rosnefts sechin miss hearing exminister corrup...  \n",
       "509              news  trump supporter phoenix threatened john mccain...  \n",
       "8988     politicsnews                 donald trump going golf par course  \n",
       "15101       worldnews  german party see momentum coalition talk despi...  \n",
       "\n",
       "[44689 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_date.to_csv('Preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "label                0\n",
      "cleaned_text       632\n",
      "cleaned_subject      0\n",
      "cleaned_title        0\n",
      "dtype: int64\n",
      "Total missing values in the dataset: 632\n"
     ]
    }
   ],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv('Preprocessed.csv')\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# Print the number of missing values in each column\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values_count)\n",
    "\n",
    "# Calculate the total number of missing values in the DataFrame\n",
    "total_missing_values = missing_values_count.sum()\n",
    "print(\"Total missing values in the dataset:\", total_missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that our models and other features are able to be included and understood, we remove the rows with missing values below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (44689, 4)\n",
      "New DataFrame shape after removing rows with NaN: (44057, 4)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values in cleaned_text as seen from the printout above\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new file if needed\n",
    "df_cleaned.to_csv('Preprocessed_clean.csv', index=False)\n",
    "\n",
    "# Optionally, print the shape to see how many rows were dropped\n",
    "print(\"Original DataFrame shape:\", df.shape)\n",
    "print(\"New DataFrame shape after removing rows with NaN:\", df_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we vectorize the dataset to enable counting tokens in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                       cleaned_text cleaned_subject  \\\n",
      "0      1  legendary journalist dan rather say robert mue...            news   \n",
      "1      0  mogadishu reuters 200 people killed twin bomb ...       worldnews   \n",
      "2      0  washington reuters member republican majority ...    politicsnews   \n",
      "3      1  big name security state sovereignty tennessee ...        politics   \n",
      "4      1  martin luther king iii met presidentelect dona...        politics   \n",
      "\n",
      "                                       cleaned_title  token_count  \n",
      "0  dan rather muellers russia investigation trump...           59  \n",
      "1  death toll blast somalia capital mogadishu top...           71  \n",
      "2  u house republican discus whether impeach irs ...           74  \n",
      "3    big tennessee vote sue fed refugee resettlement           45  \n",
      "4  high road martin luther king iii meet trump ti...           30  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load your dataset\n",
    "subset_df = pd.read_csv('Preprocessed_clean.csv')\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=512)  # You can adjust this if needed\n",
    "\n",
    "# Apply TF-IDF to the 'cleaned_text' column\n",
    "tfidf_matrix = vectorizer.fit_transform(subset_df['cleaned_text'])\n",
    "\n",
    "# Convert TF-IDF matrix to a DataFrame to manipulate easily\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Count non-zero entries in each row, which represents the number of unique tokens used\n",
    "subset_df['token_count'] = (tfidf_df != 0).sum(axis=1)\n",
    "\n",
    "# Filter out rows where the number of tokens is greater than 512\n",
    "filtered_df = subset_df[subset_df['token_count'] <= 512]\n",
    "\n",
    "# Save the filtered DataFrame\n",
    "filtered_df.to_csv('filtered_dataset.csv', index=False)\n",
    "\n",
    "# Optionally, inspect the first few rows of the filtered DataFrame\n",
    "print(filtered_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        59\n",
      "1        71\n",
      "2        74\n",
      "3        45\n",
      "4        30\n",
      "         ..\n",
      "44052    42\n",
      "44053    74\n",
      "44054    52\n",
      "44055    77\n",
      "44056    75\n",
      "Name: token_count, Length: 44057, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['token_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the printed results none of the rows have been removed, as none of them are above 512\n",
    "Below we examine the token_count, to determine wether we are able to use this as a way to create subsets and decrease the size of the dataset\n",
    "We will examine it by looking at both the lowest and highest token_count to ensure we incorporate relevant articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                       cleaned_text  \\\n",
      "18670      1  funny secret travel start believe bleed lyric ...   \n",
      "23908      1  funny secret travel start believe bleed lyric ...   \n",
      "\n",
      "      cleaned_subject                                      cleaned_title  \\\n",
      "18670          usnews  medium tripwire ping pong pizza conspiracy pro...   \n",
      "23908      middleeast  medium tripwire ping pong pizza conspiracy pro...   \n",
      "\n",
      "       token_count  \n",
      "18670          360  \n",
      "23908          360  \n",
      "       label                                       cleaned_text  \\\n",
      "635        1  httpstwittercomriggsreportstatus79868622488195...   \n",
      "1502       1  httpsfedupwpenginecomwpcontentuploads201504hil...   \n",
      "1755       1                httpswwwyoutubecomwatchvpjeoojypnck   \n",
      "1777       1  inherent vice capitalism unequal sharing bless...   \n",
      "2323       1                httpswwwyoutubecomwatchvswbypij7cq8   \n",
      "...      ...                                                ...   \n",
      "42166      1                                      karma bite ya   \n",
      "42989      1  https100percentfedupcom12yroldblackconservativ...   \n",
      "43076      1                httpswwwyoutubecomwatchv0cvugq2gbbk   \n",
      "43449      1                                           divide u   \n",
      "43686      1                                        lefty loser   \n",
      "\n",
      "       cleaned_subject                                      cleaned_title  \\\n",
      "635           politics  oh look new yorkers dont hate trump much mediu...   \n",
      "1502          leftnews  httpsfedupwpenginecomwpcontentuploads201504hil...   \n",
      "1755          leftnews  newt gingrich punch back democrat mega dos tru...   \n",
      "1777   government news  watters world video asks bernie sander support...   \n",
      "2323          politics  insanity harry reid claim putin comey conspire...   \n",
      "...                ...                                                ...   \n",
      "42166         leftnews       detroit entitled squatter get squatted video   \n",
      "42989         politics  https100percentfedupcom12yroldblackconservativ...   \n",
      "43076         politics  kellyanne conway trump terrorism policy need c...   \n",
      "43449         politics  working class revolt old school jersey patriot...   \n",
      "43686         politics  antitrump protester scream profanity fox news ...   \n",
      "\n",
      "       token_count  \n",
      "635              0  \n",
      "1502             0  \n",
      "1755             0  \n",
      "1777             0  \n",
      "2323             0  \n",
      "...            ...  \n",
      "42166            0  \n",
      "42989            0  \n",
      "43076            0  \n",
      "43449            0  \n",
      "43686            0  \n",
      "\n",
      "[134 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the row with the maximum 'token_count'\n",
    "max_token_row = filtered_df[filtered_df['token_count'] == filtered_df['token_count'].max()]\n",
    "\n",
    "# Find the row with the minimum 'token_count'\n",
    "min_token_row = filtered_df[filtered_df['token_count'] == filtered_df['token_count'].min()]\n",
    "\n",
    "# Print the row with the maximum and minimum token count\n",
    "print(max_token_row)\n",
    "print(min_token_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can clearly see many rows seem to have 0 tokens, which means these are not understood well by the computer\n",
    "This show a relevance in setting a minimum token_count and creating a subset based on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset shape: (13834, 5)\n",
      "Class distribution in subset:\n",
      " 1    6917\n",
      "0    6917\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a minimum token count threshold\n",
    "MIN_TOKENS = 70\n",
    "\n",
    "# determine that the DataFrame should include only rows with 'token_count' being greater than or equal to MIN_TOKENS\n",
    "filter_df_tokens = filtered_df[filtered_df['token_count'] >= MIN_TOKENS]\n",
    "\n",
    "# Split the DataFrame into two based on the label\n",
    "tokens_df_class_0 = filter_df_tokens[filter_df_tokens['label'] == 0]\n",
    "tokens_df_class_1 = filter_df_tokens[filter_df_tokens['label'] == 1]\n",
    "\n",
    "# Find the minimum count to balance the dataset\n",
    "min_count = min(len(tokens_df_class_0), len(tokens_df_class_1))\n",
    "\n",
    "# Randomly sample min_count rows from each DataFrame\n",
    "subset_class_0 = tokens_df_class_0.sample(n=min_count, random_state=42)  # Ensures reproducibility\n",
    "subset_class_1 = tokens_df_class_1.sample(n=min_count, random_state=42)\n",
    "\n",
    "# Concatenate the two subsets to form a new balanced DataFrame\n",
    "balanced_subset = pd.concat([subset_class_0, subset_class_1])\n",
    "\n",
    "# Shuffle the rows to ensure random order\n",
    "final_subset = balanced_subset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Optionally, save the subset to a new CSV file\n",
    "final_subset.to_csv('balanced_subset.csv', index=False)\n",
    "\n",
    "# Print some information about the subset\n",
    "print(\"Subset shape:\", final_subset.shape)\n",
    "print(\"Class distribution in subset:\\n\", final_subset['label'].value_counts())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e8995cc79525bd2f03bf06fe7351d86fcc477a350b98b661267de2f13aa6250"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
