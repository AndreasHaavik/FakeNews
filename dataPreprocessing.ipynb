{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Understanding and Preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('Fake.csv')\n",
    "true = pd.read_csv('True.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21417"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake)\n",
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "21412  'Fully committed' NATO backs new U.S. approach...   \n",
       "21413  LexisNexis withdrew two products from Chinese ...   \n",
       "21414  Minsk cultural hub becomes haven from authorities   \n",
       "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
       "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text    subject  \\\n",
       "0      Donald Trump just couldn t wish all Americans ...       News   \n",
       "1      House Intelligence Committee Chairman Devin Nu...       News   \n",
       "2      On Friday, it was revealed that former Milwauk...       News   \n",
       "3      On Christmas day, Donald Trump announced that ...       News   \n",
       "4      Pope Francis used his annual Christmas Day mes...       News   \n",
       "...                                                  ...        ...   \n",
       "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...  worldnews   \n",
       "21413  LONDON (Reuters) - LexisNexis, a provider of l...  worldnews   \n",
       "21414  MINSK (Reuters) - In the shadow of disused Sov...  worldnews   \n",
       "21415  MOSCOW (Reuters) - Vatican Secretary of State ...  worldnews   \n",
       "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...  worldnews   \n",
       "\n",
       "                    date  label  \n",
       "0      December 31, 2017      1  \n",
       "1      December 31, 2017      1  \n",
       "2      December 30, 2017      1  \n",
       "3      December 29, 2017      1  \n",
       "4      December 25, 2017      1  \n",
       "...                  ...    ...  \n",
       "21412   August 22, 2017       0  \n",
       "21413   August 22, 2017       0  \n",
       "21414   August 22, 2017       0  \n",
       "21415   August 22, 2017       0  \n",
       "21416   August 22, 2017       0  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake['label'] = 1\n",
    "true['label']=0\n",
    "\n",
    "df_concated = pd.concat([fake, true])\n",
    "permutation = np.random.permutation(len(df_concated))\n",
    "df = df_concated.iloc[permutation]\n",
    "df_concated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44689, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = df.isnull().sum()\n",
    "\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>Clinton: 'I will be there' for presidential de...</td>\n",
       "      <td>ASHLAND, Ohio (Reuters) - Democratic president...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>Merkel signals readiness for new election afte...</td>\n",
       "      <td>BERLIN (Reuters) - Chancellor Angela Merkel sa...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22815</th>\n",
       "      <td>Lavrov to Trump: ‘Do Not Attack Venezuela’</td>\n",
       "      <td>21st Century Wire says Last Friday, President ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>Trump White House Wishes ‘Lasting Peach’ In T...</td>\n",
       "      <td>Donald Trump hires all the best people, at lea...</td>\n",
       "      <td>News</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20671</th>\n",
       "      <td>WATCH: TWO TX SCHOOL WORKERS FIRED For Refusin...</td>\n",
       "      <td>Because 6 year old girls are consumed with the...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19165</th>\n",
       "      <td>Iran says Guards attack Islamic State with dro...</td>\n",
       "      <td>DUBAI (Reuters) - Iran s Revolutionary Guards ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13863</th>\n",
       "      <td>Former Zimbabwe finmin Chombo detained until b...</td>\n",
       "      <td>HARARE (Reuters) - Ousted Zimbabwe finance min...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>Greek top court to decide Dec. 13 on Russia cy...</td>\n",
       "      <td>ATHENS (Reuters) - Greece s Supreme Court will...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19073</th>\n",
       "      <td>SERIOUSLY? PRO-ILLEGAL ALIEN Supporters Demand...</td>\n",
       "      <td>The video begins with a clearly agitated pro-i...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>WOW! HILLARY Took State Department Furniture T...</td>\n",
       "      <td>Most of the documents are testimonies provided...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "8576   Clinton: 'I will be there' for presidential de...   \n",
       "14298  Merkel signals readiness for new election afte...   \n",
       "22815         Lavrov to Trump: ‘Do Not Attack Venezuela’   \n",
       "1374    Trump White House Wishes ‘Lasting Peach’ In T...   \n",
       "20671  WATCH: TWO TX SCHOOL WORKERS FIRED For Refusin...   \n",
       "...                                                  ...   \n",
       "19165  Iran says Guards attack Islamic State with dro...   \n",
       "13863  Former Zimbabwe finmin Chombo detained until b...   \n",
       "13007  Greek top court to decide Dec. 13 on Russia cy...   \n",
       "19073  SERIOUSLY? PRO-ILLEGAL ALIEN Supporters Demand...   \n",
       "12701  WOW! HILLARY Took State Department Furniture T...   \n",
       "\n",
       "                                                    text       subject  label  \n",
       "8576   ASHLAND, Ohio (Reuters) - Democratic president...  politicsNews      0  \n",
       "14298  BERLIN (Reuters) - Chancellor Angela Merkel sa...     worldnews      0  \n",
       "22815  21st Century Wire says Last Friday, President ...   Middle-east      1  \n",
       "1374   Donald Trump hires all the best people, at lea...          News      1  \n",
       "20671  Because 6 year old girls are consumed with the...     left-news      1  \n",
       "...                                                  ...           ...    ...  \n",
       "19165  DUBAI (Reuters) - Iran s Revolutionary Guards ...     worldnews      0  \n",
       "13863  HARARE (Reuters) - Ousted Zimbabwe finance min...     worldnews      0  \n",
       "13007  ATHENS (Reuters) - Greece s Supreme Court will...     worldnews      0  \n",
       "19073  The video begins with a clearly agitated pro-i...     left-news      1  \n",
       "12701  Most of the documents are testimonies provided...      politics      1  \n",
       "\n",
       "[44689 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_date = df.drop(columns=['date'])\n",
    "\n",
    "df_no_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make text Preprocessing, where are going through these steps: \n",
    "* Lowercasing\n",
    "* Removing Special Characters and Punctuation\n",
    "* Tokenization\n",
    "* Removing Stopwords\n",
    "* Lemmatization (We'll prefer this over stemming as it's generally more effective for understanding the context of words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/claramillekalo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/claramillekalo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/claramillekalo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')  # for tokenization\n",
    "nltk.download('stopwords')  # for stopwords\n",
    "nltk.download('wordnet')  # for lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_subject(subject):\n",
    "    # Convert text to lowercase\n",
    "    subject = subject.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    subject = ''.join(char for char in subject if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(subject)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_title(title):\n",
    "    # Convert text to lowercase\n",
    "    title = title.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    title = ''.join(char for char in title if char.isalnum() or char.isspace())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(title)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join words back to form the cleaned text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it contains a column named 'text'\n",
    "df_no_date['cleaned_text'] = df_no_date['text'].apply(preprocess_text)\n",
    "df_no_date['cleaned_subject'] = df_no_date['subject'].apply(preprocess_subject)\n",
    "df_no_date['cleaned_title'] = df_no_date['title'].apply(preprocess_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_date.drop(columns=['title', 'subject', 'text'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_subject</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>0</td>\n",
       "      <td>ashland ohio reuters democratic presidential c...</td>\n",
       "      <td>politicsnews</td>\n",
       "      <td>clinton presidential debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>0</td>\n",
       "      <td>berlin reuters chancellor angela merkel said w...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>merkel signal readiness new election coalition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22815</th>\n",
       "      <td>1</td>\n",
       "      <td>21st century wire say last friday president do...</td>\n",
       "      <td>middleeast</td>\n",
       "      <td>lavrov trump attack venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1</td>\n",
       "      <td>donald trump hire best people least promised n...</td>\n",
       "      <td>news</td>\n",
       "      <td>trump white house wish lasting peach middle ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20671</th>\n",
       "      <td>1</td>\n",
       "      <td>6 year old girl consumed sexual identity right...</td>\n",
       "      <td>leftnews</td>\n",
       "      <td>watch two tx school worker fired refusing call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19165</th>\n",
       "      <td>0</td>\n",
       "      <td>dubai reuters iran revolutionary guard sunday ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>iran say guard attack islamic state drone east...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13863</th>\n",
       "      <td>0</td>\n",
       "      <td>harare reuters ousted zimbabwe finance ministe...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>former zimbabwe finmin chombo detained bail he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>0</td>\n",
       "      <td>athens reuters greece supreme court decide dec...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>greek top court decide dec 13 russia cyber sus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19073</th>\n",
       "      <td>1</td>\n",
       "      <td>video begin clearly agitated proillegal alien ...</td>\n",
       "      <td>leftnews</td>\n",
       "      <td>seriously proillegal alien supporter demand co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>1</td>\n",
       "      <td>document testimony provided federal investigat...</td>\n",
       "      <td>politics</td>\n",
       "      <td>wow hillary took state department furniture fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       cleaned_text  \\\n",
       "8576       0  ashland ohio reuters democratic presidential c...   \n",
       "14298      0  berlin reuters chancellor angela merkel said w...   \n",
       "22815      1  21st century wire say last friday president do...   \n",
       "1374       1  donald trump hire best people least promised n...   \n",
       "20671      1  6 year old girl consumed sexual identity right...   \n",
       "...      ...                                                ...   \n",
       "19165      0  dubai reuters iran revolutionary guard sunday ...   \n",
       "13863      0  harare reuters ousted zimbabwe finance ministe...   \n",
       "13007      0  athens reuters greece supreme court decide dec...   \n",
       "19073      1  video begin clearly agitated proillegal alien ...   \n",
       "12701      1  document testimony provided federal investigat...   \n",
       "\n",
       "      cleaned_subject                                      cleaned_title  \n",
       "8576     politicsnews                        clinton presidential debate  \n",
       "14298       worldnews  merkel signal readiness new election coalition...  \n",
       "22815      middleeast                      lavrov trump attack venezuela  \n",
       "1374             news  trump white house wish lasting peach middle ea...  \n",
       "20671        leftnews  watch two tx school worker fired refusing call...  \n",
       "...               ...                                                ...  \n",
       "19165       worldnews  iran say guard attack islamic state drone east...  \n",
       "13863       worldnews  former zimbabwe finmin chombo detained bail he...  \n",
       "13007       worldnews  greek top court decide dec 13 russia cyber sus...  \n",
       "19073        leftnews  seriously proillegal alien supporter demand co...  \n",
       "12701        politics  wow hillary took state department furniture fu...  \n",
       "\n",
       "[44689 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_date.to_csv('Preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "label                0\n",
      "cleaned_text       632\n",
      "cleaned_subject      0\n",
      "cleaned_title        0\n",
      "dtype: int64\n",
      "Total missing values in the dataset: 632\n"
     ]
    }
   ],
   "source": [
    "# Loading DataFrame to check for missing values\n",
    "df = pd.read_csv('Preprocessed.csv')\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# Print the number of missing values in each column\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values_count)\n",
    "\n",
    "# Calculate the total number of missing values in the DataFrame\n",
    "total_missing_values = missing_values_count.sum()\n",
    "print(\"Total missing values in the dataset:\", total_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that our models and other features are able to be included and understood, we remove the rows with missing values below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (44689, 4)\n",
      "New DataFrame shape after removing rows with NaN: (44057, 4)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values in cleaned_text as seen from the printout above\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new file if needed\n",
    "df_cleaned.to_csv('Preprocessed_clean.csv', index=False)\n",
    "\n",
    "# Optionally, print the shape to see how many rows were dropped\n",
    "print(\"Original DataFrame shape:\", df.shape)\n",
    "print(\"New DataFrame shape after removing rows with NaN:\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we vectorize the dataset to enable counting tokens in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                       cleaned_text cleaned_subject  \\\n",
      "0      0  ashland ohio reuters democratic presidential c...    politicsnews   \n",
      "1      0  berlin reuters chancellor angela merkel said w...       worldnews   \n",
      "2      1  21st century wire say last friday president do...      middleeast   \n",
      "3      1  donald trump hire best people least promised n...            news   \n",
      "4      1  6 year old girl consumed sexual identity right...        leftnews   \n",
      "\n",
      "                                       cleaned_title  token_count  \n",
      "0                        clinton presidential debate           21  \n",
      "1  merkel signal readiness new election coalition...          119  \n",
      "2                      lavrov trump attack venezuela           57  \n",
      "3  trump white house wish lasting peach middle ea...           68  \n",
      "4  watch two tx school worker fired refusing call...           44  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load your dataset\n",
    "subset_df = pd.read_csv('Preprocessed_clean.csv')\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=512)  # You can adjust this if needed\n",
    "\n",
    "# Apply TF-IDF to the 'cleaned_text' column\n",
    "tfidf_matrix = vectorizer.fit_transform(subset_df['cleaned_text'])\n",
    "\n",
    "# Convert TF-IDF matrix to a DataFrame to manipulate easily\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Count non-zero entries in each row, which represents the number of unique tokens used\n",
    "subset_df['token_count'] = (tfidf_df != 0).sum(axis=1)\n",
    "\n",
    "# Filter out rows where the number of tokens is greater than 512\n",
    "filtered_df = subset_df[subset_df['token_count'] <= 512]\n",
    "\n",
    "# Save the filtered DataFrame\n",
    "filtered_df.to_csv('filtered_dataset.csv', index=False)\n",
    "\n",
    "# Optionally, inspect the first few rows of the filtered DataFrame\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         21\n",
      "1        119\n",
      "2         57\n",
      "3         68\n",
      "4         44\n",
      "        ... \n",
      "44052     18\n",
      "44053     21\n",
      "44054     32\n",
      "44055     41\n",
      "44056     28\n",
      "Name: token_count, Length: 44057, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['token_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the printed results none of the rows have been removed, as none of them are above 512 Below we examine the token_count, to determine wether we are able to use this as a way to create subsets and decrease the size of the dataset We will examine it by looking at both the lowest and highest token_count to ensure we incorporate relevant articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                       cleaned_text  \\\n",
      "22467      1  funny secret travel start believe bleed lyric ...   \n",
      "43586      1  funny secret travel start believe bleed lyric ...   \n",
      "\n",
      "      cleaned_subject                                      cleaned_title  \\\n",
      "22467          usnews  medium tripwire ping pong pizza conspiracy pro...   \n",
      "43586      middleeast  medium tripwire ping pong pizza conspiracy pro...   \n",
      "\n",
      "       token_count  \n",
      "22467          360  \n",
      "43586          360  \n",
      "       label                                       cleaned_text  \\\n",
      "26         1  httpswwwyoutubecomwatchfeatureplayerembeddedvj...   \n",
      "569        1  httpsfedupwpenginecomwpcontentuploads201504hil...   \n",
      "1057       1  probably explains love guy muchstrong language...   \n",
      "1586       1                httpswwwyoutubecomwatchvuqbaww5waja   \n",
      "1715       1              charlie leduff legend detroit classic   \n",
      "...      ...                                                ...   \n",
      "41856      1                httpswwwyoutubecomwatchvj4ljxrofef8   \n",
      "41919      1                  httpswwwyoutubecomwatchvfnt3nsega   \n",
      "41982      1                httpswwwyoutubecomwatchvwydx071nlow   \n",
      "43728      1                httpswwwyoutubecomwatchv6vn1mabekik   \n",
      "44046      1                                            wow wow   \n",
      "\n",
      "       cleaned_subject                                      cleaned_title  \\\n",
      "26            politics  rep peter king intel community carrying disinf...   \n",
      "569           leftnews  httpsfedupwpenginecomwpcontentuploads201504hil...   \n",
      "1057          leftnews  lol trigger liberal halloween make costume tas...   \n",
      "1586          politics  brilliant tucker carlson humiliates jill stein...   \n",
      "1715   government news  comedy gold detroit news willy dump tire wrong...   \n",
      "...                ...                                                ...   \n",
      "41856         politics  wow tucker jesse destroy liberal kook protesti...   \n",
      "41919         politics  unreal cnn panel laugh mock dr ben carson trum...   \n",
      "41982         leftnews  give em hell jesse shouldnt democrat start foc...   \n",
      "43728         politics  watch kellyanne conway v total jerk chris cuom...   \n",
      "44046         politics  rush limbaugh warns gop choose trump cruz dont...   \n",
      "\n",
      "       token_count  \n",
      "26               0  \n",
      "569              0  \n",
      "1057             0  \n",
      "1586             0  \n",
      "1715             0  \n",
      "...            ...  \n",
      "41856            0  \n",
      "41919            0  \n",
      "41982            0  \n",
      "43728            0  \n",
      "44046            0  \n",
      "\n",
      "[134 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the row with the maximum 'token_count'\n",
    "max_token_row = filtered_df[filtered_df['token_count'] == filtered_df['token_count'].max()]\n",
    "\n",
    "# Find the row with the minimum 'token_count'\n",
    "min_token_row = filtered_df[filtered_df['token_count'] == filtered_df['token_count'].min()]\n",
    "\n",
    "# Print the row with the maximum and minimum token count\n",
    "print(max_token_row)\n",
    "print(min_token_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can clearly see many rows seem to have 0 tokens, which means these are not understood well by the computer This show a relevance in setting a minimum token_count and creating a subset based on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset shape: (13834, 5)\n",
      "Class distribution in subset:\n",
      " 1    6917\n",
      "0    6917\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a minimum token count threshold\n",
    "MIN_TOKENS = 70\n",
    "\n",
    "# determine that the DataFrame should include only rows with 'token_count' being greater than or equal to MIN_TOKENS\n",
    "filter_df_tokens = filtered_df[filtered_df['token_count'] >= MIN_TOKENS]\n",
    "\n",
    "# Split the DataFrame into two based on the label\n",
    "tokens_df_class_0 = filter_df_tokens[filter_df_tokens['label'] == 0]\n",
    "tokens_df_class_1 = filter_df_tokens[filter_df_tokens['label'] == 1]\n",
    "\n",
    "# Find the minimum count to balance the dataset\n",
    "min_count = min(len(tokens_df_class_0), len(tokens_df_class_1))\n",
    "\n",
    "# Randomly sample min_count rows from each DataFrame\n",
    "subset_class_0 = tokens_df_class_0.sample(n=min_count, random_state=42)  # Ensures reproducibility\n",
    "subset_class_1 = tokens_df_class_1.sample(n=min_count, random_state=42)\n",
    "\n",
    "# Concatenate the two subsets to form a new balanced DataFrame\n",
    "balanced_subset = pd.concat([subset_class_0, subset_class_1])\n",
    "\n",
    "# Shuffle the rows to ensure random order\n",
    "final_subset = balanced_subset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Optionally, save the subset to a new CSV file\n",
    "final_subset.to_csv('text_balanced_subset.csv', index=False)\n",
    "\n",
    "# Print some information about the subset\n",
    "print(\"Subset shape:\", final_subset.shape)\n",
    "print(\"Class distribution in subset:\\n\", final_subset['label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e8995cc79525bd2f03bf06fe7351d86fcc477a350b98b661267de2f13aa6250"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
